# P2 Phase 2: 근본 설계 개선 RFC

**날짜**: 2025-10-07
**상태**: 🟢 승인됨 (Approved)
**작성자**: Claude Code
**검토자**: Architecture Team

---

## Executive Summary

**목표**: P2 품질 이슈를 "증상 치료"가 아닌 "근본 설계 개선"으로 해결

| 지표                   | 현재         | 목표       | 설계 개선                                     |
| ---------------------- | ------------ | ---------- | --------------------------------------------- |
| **엔티티 커버리지**    | 46.7%        | 85%+       | NER + 도메인 사전 + Agent 통합                |
| **Evidence Alignment** | ~46%         | 85%+       | 의미 기반 정렬 + 직접 인용 강화 + 피드백 루프 |
| **질문 유형 분류**     | ✅ 수정 완료 | 4가지 균형 | Agent 계층 연동                               |

**핵심 아이디어**:

1. **계층 재구조화**: domain/ 생성 (extraction/alignment/classification)
2. **Agent 통합**: Diversity Planner 생성 (품질 목표 설정)
3. **피드백 루프**: 품질 검증 → Regeneration (최대 3회)
4. **LLM 활용 강화**: 규칙 기반 → 의미 이해

---

## 1. 현재 아키텍처 분석

### 1.1 Dependency Graph

```
┌────────────────────────────────────────────────────┐
│ calculateDetailedMetrics (scripts/metrics/__all__) │
└────────────────┬───────────────────────────────────┘
                 │
                 ├─► duplicationMetrics.ts       (중복 검사)
                 ├─► qtypeDistribution.ts        (질문 유형 분류) ✅ 수정 완료
                 ├─► coverageMetrics.ts          (엔티티 커버리지) ⚠️ 개선 필요
                 ├─► evidenceQuality.ts          (증거 정렬) ⚠️ 개선 필요
                 ├─► hallucinationRules.ts       (환각 검사)
                 └─► piiLicenseScan.ts           (PII/라이센스)
```

### 1.2 핵심 문제점

#### A. 엔티티 커버리지 (coverageMetrics.ts)

**현재 구현**:

```typescript
// Line 61-96: 단순 n-gram 추출
function extractKeyPhrases(
  text: string,
  minLength: number,
  maxLength: number,
): string[] {
  const normalized = text
    .toLowerCase()
    .replace(/[^\w\s가-힣]/g, " ") // ❌ 한자 제거됨!
    .trim();

  // n-gram 추출 (1-3 단어)
  for (let n = minLength; n <= maxLength; n++) {
    for (let i = 0; i <= words.length - n; i++) {
      const phrase = words.slice(i, i + n).join(" ");
      phrases.push(phrase);
    }
  }

  return phrases; // ❌ 빈도순 정렬, NER 없음
}
```

**문제**:

1. **한자 처리 부재**: "구이디" (본명) → 정규식에서 제거됨
2. **복합어 처리 실패**: "건축에서의" → 분리 안 됨
3. **고유명사 인식 없음**: "브루넬레스키나" → 일반 n-gram으로만 처리
4. **빈도 기반 추출**: 중요하지만 빈도 낮은 엔티티 누락

**결과**: 46.7% 커버리지 (목표 50% 미달)

#### B. Evidence Alignment (evidenceQuality.ts)

**현재 구현**:

```typescript
// Line 157-178: 단순 문자 기반 유사도
function calculateSnippetAlignment(
  answer: string,
  evidence: string,
  config: EvidenceConfig,
): number {
  // 1. n-gram overlap (3-gram)
  const ngramOverlap = calculateNgramOverlap(answer, evidence, 3);

  // 2. Character-level cosine similarity
  const cosineSim = calculateCosineSimilarity(answer, evidence);

  // 3. 가중 평균 (40% + 60%)
  const alignmentScore = ngramOverlap * 0.4 + cosineSim * 0.6;

  return Math.min(alignmentScore, 1.0);
}
```

**문제**:

1. **의미 무시**: "브루넬레스키와 함께" ≠ "15세기 초 유행하던 국제고딕양식"

   - 문자적으로 완전히 다름 → Alignment 0%
   - 하지만 의미상 관련있음 (Evidence에서 추론 가능)

2. **의역 처리 불가**:

   ```
   Evidence: "브루넬레스키나 도나텔로와 함께"
   Answer: "마사초는 15세기 초 유행하던 국제고딕양식을 따르지 않았어요"
   Alignment: 26.9% ❌
   ```

   - 답변이 Evidence를 의역/확장 → 문자 매칭 실패

3. **인용구 추출 없음**: 직접 인용 부분을 감지하지 못함

**결과**: ~46% Alignment (목표 60% 미달)

#### C. Agent-Metric 분리

**현재 구조**:

```
src/
├── agents/          # QA 생성 (메트릭 무관)
│   ├── qaGenerator.ts
│   └── ...
│
├── scripts/metrics/ # 메트릭 계산 (사후 평가만)
│   ├── coverageMetrics.ts
│   ├── evidenceQuality.ts
│   └── qtypeDistribution.ts
│
└── tools/           # 외부 도구 (미통합)
    └── diversity_analyzer.js
```

**문제**:

- QA 생성 시 품질 목표를 고려하지 못함
- Metric 계산은 사후 평가만 가능
- **피드백 루프 부재** ← 가장 큰 문제
- Diversity Planner Agent 부재 (계획에는 있지만 미구현)

---

## 2. 설계 개선 전략

### 2.1 계층 재구조화

#### Before (분산됨)

```
src/
├── agents/          # QA 생성
├── scripts/metrics/ # 메트릭 (사후)
└── tools/           # 외부 도구
```

#### After (통합됨)

```
src/
├── domain/                         # 도메인 로직 (새로 생성)
│   ├── extraction/                 # 엔티티 추출
│   │   ├── entity-recognizer.ts    # NER 인터페이스
│   │   ├── korean-ner.ts           # 한국어 특화 NER
│   │   ├── entity-dictionary.ts    # 도메인 사전
│   │   └── composite-extractor.ts  # NER + 사전 결합
│   │
│   ├── alignment/                  # 증거 정렬
│   │   ├── semantic-aligner.ts     # 의미 기반 정렬 인터페이스
│   │   ├── lexical-aligner.ts      # 기존 문자 기반 (fallback)
│   │   ├── llm-aligner.ts          # LLM 기반 의미 정렬
│   │   └── citation-detector.ts    # 직접 인용 검출
│   │
│   └── classification/             # 질문 유형 분류
│       ├── question-classifier.ts  # 분류 인터페이스
│       ├── pattern-classifier.ts   # 기존 정규식 기반
│       └── llm-classifier.ts       # LLM 기반 분류 (향후)
│
├── agents/
│   ├── qaGenerator.ts              # QA 생성 (기존)
│   └── diversityPlanner.ts         # 품질 목표 설정 (신규) ⭐
│
└── scripts/metrics/                # 검증만 담당
    ├── coverageMetrics.ts          # domain/extraction 사용
    ├── evidenceQuality.ts          # domain/alignment 사용
    └── qtypeDistribution.ts        # domain/classification 사용
```

**핵심 변화**:

1. **domain/ 계층 신규 생성**: 도메인 로직 캡슐화
2. **Diversity Planner Agent 추가**: 품질 목표 설정 및 계획
3. **metrics는 검증만 담당**: 도메인 로직 재사용

### 2.2 Diversity Planner Agent 설계

**역할**: QA 생성 전 품질 목표 설정 및 전략 수립

```typescript
// src/agents/diversityPlanner.ts (신규)

export interface DiversityPlan {
  // 엔티티 커버리지 목표
  entityCoverage: {
    targetRate: number; // 85%
    targetEntities: Entity[]; // NER + 사전 결합
    coverageStrategy: string; // "balanced" | "priority"
  };

  // Evidence Alignment 목표
  evidenceAlignment: {
    minScore: number; // 0.85
    alignmentStrategy: string; // "direct_quote" | "paraphrase"
    citationRequirement: boolean; // true
  };

  // 질문 유형 목표
  questionTypeDistribution: {
    analytical: number; // 30%
    procedural: number; // 30%
    comparative: number; // 20%
    factual: number; // 20%
  };

  // 생성 계획
  generationPlan: GenerationTask[];
}

export interface GenerationTask {
  taskId: string;
  type: "analytical" | "procedural" | "comparative" | "factual";
  targetEntity?: Entity; // 커버할 엔티티
  evidenceSnippet: string; // 사용할 Evidence
  qualityRequirements: {
    minAlignmentScore: number; // 0.85
    requireDirectQuote: boolean; // true
    maxRegenerationAttempts: number; // 3
  };
}

export class DiversityPlanner extends BaseAgent {
  private ner: CompositeExtractor;
  private aligner: SemanticAligner;
  private classifier: QuestionClassifier;

  constructor() {
    super("diversityPlanner", "Diversity planning and quality target setting");
    this.ner = new CompositeExtractor();
    this.aligner = new LexicalAligner(); // fallback
    this.classifier = new PatternClassifier();
  }

  async planDiversity(
    sourceTexts: string[],
    domain: string,
    targetCount: number,
  ): Promise<DiversityPlan> {
    // 1. 엔티티 추출 (NER + 사전 결합)
    const entities = await this.ner.extractEntities(sourceTexts, domain);

    // 2. 엔티티 우선순위 결정
    const targetEntities = this.selectTargetEntities(entities, 0.85); // 85% 목표

    // 3. 질문 유형 분포 계획
    const typeDistribution = {
      analytical: Math.floor(targetCount * 0.3),
      procedural: Math.floor(targetCount * 0.3),
      comparative: Math.floor(targetCount * 0.2),
      factual: Math.floor(targetCount * 0.2),
    };

    // 4. 생성 계획 수립
    const generationPlan = this.createGenerationPlan(
      targetEntities,
      typeDistribution,
      sourceTexts,
    );

    return {
      entityCoverage: {
        targetRate: 0.85,
        targetEntities,
        coverageStrategy: "balanced",
      },
      evidenceAlignment: {
        minScore: 0.85,
        alignmentStrategy: "direct_quote",
        citationRequirement: true,
      },
      questionTypeDistribution: typeDistribution,
      generationPlan,
    };
  }

  private selectTargetEntities(
    entities: Entity[],
    targetRate: number,
  ): Entity[] {
    // 신뢰도 기반 정렬
    const sorted = entities.sort((a, b) => b.confidence - a.confidence);

    // 상위 N개 선택 (목표 커버리지 달성)
    const count = Math.ceil(entities.length * targetRate);
    return sorted.slice(0, count);
  }

  private createGenerationPlan(
    targetEntities: Entity[],
    typeDistribution: Record<string, number>,
    sourceTexts: string[],
  ): GenerationTask[] {
    const tasks: GenerationTask[] = [];

    // 각 질문 유형별로 태스크 생성
    for (const [type, count] of Object.entries(typeDistribution)) {
      for (let i = 0; i < count; i++) {
        // 엔티티 할당 (라운드로빈)
        const entity = targetEntities[tasks.length % targetEntities.length];

        // Evidence 선택 (엔티티 포함)
        const evidenceSnippet = this.selectEvidence(entity, sourceTexts);

        tasks.push({
          taskId: `task_${type}_${i}`,
          type: type as any,
          targetEntity: entity,
          evidenceSnippet,
          qualityRequirements: {
            minAlignmentScore: 0.85,
            requireDirectQuote: true,
            maxRegenerationAttempts: 3,
          },
        });
      }
    }

    return tasks;
  }

  private selectEvidence(entity: Entity, sourceTexts: string[]): string {
    // 엔티티를 포함하는 Evidence 선택
    for (const text of sourceTexts) {
      if (text.includes(entity.text)) {
        // 엔티티 주변 문맥 추출 (±50자)
        const index = text.indexOf(entity.text);
        const start = Math.max(0, index - 50);
        const end = Math.min(text.length, index + entity.text.length + 50);
        return text.substring(start, end);
      }
    }

    return sourceTexts[0]; // fallback
  }
}
```

### 2.3 피드백 루프 구축

**기존 흐름 (피드백 없음)**:

```
QA 생성 → 메트릭 계산 → 보고서 출력 (끝)
```

**개선 흐름 (피드백 루프)**:

```
┌──────────────────┐
│ Diversity Planner│
│ (목표 설정)      │
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│ QA Generator     │◄────────────────┐
│ (생성)           │                 │
└────────┬─────────┘                 │
         │                           │
         ▼                           │
┌──────────────────┐                 │
│ Quality Validator│                 │
│ (검증)           │                 │
└────────┬─────────┘                 │
         │                           │
         ▼                           │
    품질 충족?                        │
         │                           │
         ├── Yes → Accept            │
         │                           │
         └── No  → Regenerate ───────┘
                   (최대 3회)
```

**구현 예시**:

```typescript
// src/agents/qaGenerator.ts (개선)

export class QAGenerator extends BaseAgent {
  private aligner: SemanticAligner;
  private maxRegenerationAttempts = 3;

  async generateQAWithFeedback(task: GenerationTask): Promise<QAItem> {
    let attempts = 0;
    let qa: QAItem | null = null;
    let alignment: AlignmentResult | null = null;

    while (attempts < this.maxRegenerationAttempts) {
      attempts++;

      // 1. QA 생성
      qa = await this.generateQA(task);

      // 2. Alignment 검증
      alignment = await this.aligner.calculateAlignment(
        qa.a,
        task.evidenceSnippet
      );

      // 3. 품질 충족 여부 확인
      if (alignment.score >= task.qualityRequirements.minAlignmentScore) {
        // ✅ 품질 충족 → Accept
        return qa;
      }

      // ❌ 품질 미달 → Regenerate with feedback
      if (attempts < this.maxRegenerationAttempts) {
        qa = await this.regenerateWithFeedback(qa, alignment, task);
      }
    }

    // 최대 재시도 횟수 초과 → 마지막 결과 반환 (경고 포함)
    console.warn(`QA generation failed to meet quality requirements after ${attempts} attempts`);
    return qa!;
  }

  private async regenerateWithFeedback(
    failedQA: QAItem,
    alignment: AlignmentResult,
    task: GenerationTask
  ): Promise<QAItem> {
    const prompt = `
이전 답변의 Alignment가 낮습니다 (${alignment.score.toFixed(2)}).
Evidence를 **더 직접적으로 인용**하세요.

Evidence: "${task.evidenceSnippet}"
이전 답변: "${failedQA.a}"

개선 요구사항:
1. Evidence의 핵심 문장을 **그대로 포함**
2. "문서에 따르면 '${직접 인용}' 합니다" 형식 사용
3. 의역보다는 직접 인용 우선

개선된 답변:`;

    const improved = await this.llm.complete(prompt);
    return { ...failedQA, a: improved };
  }
}
```

---

## 3. Domain 계층 설계

### 3.1 Entity Extraction (domain/extraction/)

#### A. Entity Recognizer 인터페이스

```typescript
// src/domain/extraction/entity-recognizer.ts (신규)

export interface Entity {
  text: string;
  type: "PERSON" | "LOCATION" | "TERM" | "DATE" | "OTHER";
  confidence: number;
  span: [number, number];
  source: "ner" | "dictionary" | "hybrid";
}

export interface EntityRecognizer {
  extractEntities(text: string, domain?: string): Promise<Entity[]>;
}
```

#### B. Korean NER

```typescript
// src/domain/extraction/korean-ner.ts (신규)

export class KoreanNER implements EntityRecognizer {
  private patterns = {
    // 한국어 이름 (2-4자)
    person: /([가-힣]{2,4}|[A-Z][a-z]+\s*[A-Z][a-z]+)/g,

    // 지명 (시/도/국가)
    location: /(시칠리아|베네치아|밀라노|[가-힣]+시|[가-힣]+도|[가-힣]+국)/g,

    // 전문 용어
    term: /(르네상스|고딕|유화|명암표현법|원근법|국제고딕양식)/g,

    // 한자 이름 (2-4자)
    hanja: /[一-龥]{2,4}/g,

    // 날짜 (15세기, 1420년대 등)
    date: /(\d{1,2}세기|\d{4}년대?)/g,
  };

  async extractEntities(text: string, _domain?: string): Promise<Entity[]> {
    const entities: Entity[] = [];

    // 패턴 매칭
    for (const [type, pattern] of Object.entries(this.patterns)) {
      const matches = [...text.matchAll(pattern)];
      for (const match of matches) {
        entities.push({
          text: match[0],
          type: this.mapTypeToCategory(type),
          confidence: this.calculateConfidence(type),
          span: [match.index!, match.index! + match[0].length],
          source: "ner",
        });
      }
    }

    return this.deduplicateEntities(entities);
  }

  private mapTypeToCategory(patternType: string): Entity["type"] {
    const mapping: Record<string, Entity["type"]> = {
      person: "PERSON",
      hanja: "PERSON",
      location: "LOCATION",
      term: "TERM",
      date: "DATE",
    };
    return mapping[patternType] || "OTHER";
  }

  private calculateConfidence(patternType: string): number {
    // 패턴별 신뢰도
    const confidence: Record<string, number> = {
      term: 0.9, // 전문 용어는 신뢰도 높음
      hanja: 0.7, // 한자 이름은 중간
      person: 0.8, // 한글 이름은 높음
      location: 0.85, // 지명은 높음
      date: 0.95, // 날짜는 매우 높음
    };
    return confidence[patternType] || 0.5;
  }

  private deduplicateEntities(entities: Entity[]): Entity[] {
    const seen = new Map<string, Entity>();

    for (const entity of entities) {
      const key = `${entity.text}_${entity.type}`;
      const existing = seen.get(key);

      if (!existing || entity.confidence > existing.confidence) {
        seen.set(key, entity);
      }
    }

    return Array.from(seen.values());
  }
}
```

#### C. Entity Dictionary

```typescript
// src/domain/extraction/entity-dictionary.ts (신규)

export const DOMAIN_ENTITIES = {
  art_renaissance: {
    persons: [
      "마사초",
      "브루넬레스키",
      "도나텔로",
      "안토넬로",
      "두초",
      "구이디",
      "파에즈",
      "얀 반 에이크",
      "로히어 반 데르 베이덴",
    ],
    locations: [
      "시칠리아",
      "베네치아",
      "밀라노",
      "메시나",
      "시에나",
      "피렌체",
      "플랑드르",
      "네덜란드",
    ],
    terms: [
      "르네상스",
      "고딕",
      "국제고딕양식",
      "유화",
      "명암표현법",
      "원근법",
      "성상화",
      "패널화",
      "템페라",
      "제단화",
    ],
  },
  // 다른 도메인 추가 가능
};

export class DictionaryBasedExtractor implements EntityRecognizer {
  async extractEntities(
    text: string,
    domain: string = "art_renaissance",
  ): Promise<Entity[]> {
    const dict = DOMAIN_ENTITIES[domain as keyof typeof DOMAIN_ENTITIES] || {};
    const entities: Entity[] = [];

    for (const [type, keywords] of Object.entries(dict)) {
      for (const keyword of keywords as string[]) {
        const regex = new RegExp(keyword, "g");
        const matches = [...text.matchAll(regex)];

        for (const match of matches) {
          entities.push({
            text: match[0],
            type: this.mapTypeToCategory(type),
            confidence: 0.95, // 사전 기반은 신뢰도 매우 높음
            span: [match.index!, match.index! + match[0].length],
            source: "dictionary",
          });
        }
      }
    }

    return entities;
  }

  private mapTypeToCategory(dictType: string): Entity["type"] {
    const mapping: Record<string, Entity["type"]> = {
      persons: "PERSON",
      locations: "LOCATION",
      terms: "TERM",
    };
    return mapping[dictType] || "OTHER";
  }
}
```

#### D. Composite Extractor (NER + 사전 결합)

```typescript
// src/domain/extraction/composite-extractor.ts (신규)

export class CompositeExtractor implements EntityRecognizer {
  private ner: KoreanNER;
  private dict: DictionaryBasedExtractor;

  constructor() {
    this.ner = new KoreanNER();
    this.dict = new DictionaryBasedExtractor();
  }

  async extractEntities(
    texts: string[],
    domain: string = "art_renaissance",
  ): Promise<Entity[]> {
    const allEntities: Entity[] = [];

    for (const text of texts) {
      // 1. NER 추출
      const nerEntities = await this.ner.extractEntities(text);

      // 2. 사전 추출
      const dictEntities = await this.dict.extractEntities(text, domain);

      // 3. 결합
      allEntities.push(...nerEntities, ...dictEntities);
    }

    // 4. 중복 제거 및 신뢰도 병합
    return this.mergeEntities(allEntities);
  }

  private mergeEntities(entities: Entity[]): Entity[] {
    const merged = new Map<string, Entity>();

    for (const entity of entities) {
      const key = entity.text.toLowerCase();
      const existing = merged.get(key);

      if (!existing) {
        merged.set(key, entity);
      } else {
        // 더 높은 신뢰도 선택
        if (entity.confidence > existing.confidence) {
          merged.set(key, entity);
        }
        // 같은 신뢰도면 source 우선순위 (dictionary > ner > hybrid)
        else if (entity.confidence === existing.confidence) {
          if (
            entity.source === "dictionary" &&
            existing.source !== "dictionary"
          ) {
            merged.set(key, entity);
          }
        }
      }
    }

    return Array.from(merged.values()).sort(
      (a, b) => b.confidence - a.confidence,
    );
  }
}
```

### 3.2 Evidence Alignment (domain/alignment/)

#### A. Semantic Aligner 인터페이스

```typescript
// src/domain/alignment/semantic-aligner.ts (신규)

export interface AlignmentResult {
  score: number; // 0-1
  method: "direct_quote" | "paraphrase" | "inference" | "unrelated";
  confidence: number;
  matchedSpans: Array<{
    answerSpan: string;
    evidenceSpan: string;
    similarity: number;
  }>;
}

export interface SemanticAligner {
  calculateAlignment(
    answer: string,
    evidence: string,
  ): Promise<AlignmentResult>;
}
```

#### B. Citation Detector (직접 인용 검출)

```typescript
// src/domain/alignment/citation-detector.ts (신규)

export class CitationDetector {
  /**
   * 직접 인용 검출 (3-gram 이상 일치)
   */
  detectDirectQuotes(
    answer: string,
    evidence: string,
  ): Array<{
    answerSpan: string;
    evidenceSpan: string;
    similarity: number;
  }> {
    const matches: Array<{
      answerSpan: string;
      evidenceSpan: string;
      similarity: number;
    }> = [];

    // 답변을 n-gram으로 분할 (n=3~10)
    for (let n = 10; n >= 3; n--) {
      const answerNgrams = this.extractNgrams(answer, n);

      for (const ngram of answerNgrams) {
        if (evidence.includes(ngram)) {
          matches.push({
            answerSpan: ngram,
            evidenceSpan: ngram,
            similarity: 1.0,
          });
        }
      }
    }

    // 중복 제거 (긴 매칭 우선)
    return this.deduplicateMatches(matches);
  }

  private extractNgrams(text: string, n: number): string[] {
    const ngrams: string[] = [];

    // 문자 단위 n-gram (공백 제거)
    const cleaned = text.replace(/\s+/g, "");

    for (let i = 0; i <= cleaned.length - n; i++) {
      ngrams.push(cleaned.substring(i, i + n));
    }

    return ngrams;
  }

  private deduplicateMatches(
    matches: Array<{
      answerSpan: string;
      evidenceSpan: string;
      similarity: number;
    }>,
  ): Array<{ answerSpan: string; evidenceSpan: string; similarity: number }> {
    // 긴 매칭이 짧은 매칭을 포함하면 긴 것만 유지
    const sorted = matches.sort(
      (a, b) => b.answerSpan.length - a.answerSpan.length,
    );
    const deduplicated: typeof matches = [];

    for (const match of sorted) {
      const isSubsumed = deduplicated.some((existing) =>
        existing.answerSpan.includes(match.answerSpan),
      );

      if (!isSubsumed) {
        deduplicated.push(match);
      }
    }

    return deduplicated;
  }

  /**
   * 직접 인용 비율 계산
   */
  calculateDirectQuoteRatio(answer: string, evidence: string): number {
    const matches = this.detectDirectQuotes(answer, evidence);

    if (matches.length === 0) return 0;

    // 매칭된 문자 수 합산
    const totalMatchedChars = matches.reduce(
      (sum, match) => sum + match.answerSpan.length,
      0,
    );

    // 답변 전체 문자 수
    const answerLength = answer.replace(/\s+/g, "").length;

    return answerLength > 0 ? totalMatchedChars / answerLength : 0;
  }
}
```

#### C. Lexical Aligner (기존 문자 기반, fallback)

```typescript
// src/domain/alignment/lexical-aligner.ts (신규, 기존 코드 이관)

export class LexicalAligner implements SemanticAligner {
  private citationDetector: CitationDetector;

  constructor() {
    this.citationDetector = new CitationDetector();
  }

  async calculateAlignment(
    answer: string,
    evidence: string,
  ): Promise<AlignmentResult> {
    // 1. 직접 인용 검사 (우선순위 최상)
    const directQuoteRatio = this.citationDetector.calculateDirectQuoteRatio(
      answer,
      evidence,
    );

    if (directQuoteRatio >= 0.3) {
      // 30% 이상 직접 인용 → 매우 높은 점수
      return {
        score: 0.8 + directQuoteRatio * 0.2, // 0.8 ~ 1.0
        method: "direct_quote",
        confidence: 0.95,
        matchedSpans: this.citationDetector.detectDirectQuotes(
          answer,
          evidence,
        ),
      };
    }

    // 2. n-gram overlap + cosine similarity (기존 방식)
    const ngramOverlap = this.calculateNgramOverlap(answer, evidence, 3);
    const cosineSim = this.calculateCosineSimilarity(answer, evidence);
    const combinedScore = ngramOverlap * 0.4 + cosineSim * 0.6;

    // 3. 방법 분류
    let method: AlignmentResult["method"];
    if (combinedScore >= 0.5) {
      method = "paraphrase";
    } else if (combinedScore >= 0.3) {
      method = "inference";
    } else {
      method = "unrelated";
    }

    return {
      score: Math.min(combinedScore, 1.0),
      method,
      confidence: 0.7,
      matchedSpans: [],
    };
  }

  private calculateNgramOverlap(
    text1: string,
    text2: string,
    n: number,
  ): number {
    // 기존 evidenceQuality.ts의 calculateNgramOverlap 이관
    const tokens1 = text1
      .toLowerCase()
      .replace(/[^\w\s가-힣]/g, " ")
      .split(/\s+/)
      .filter((t) => t.length > 0);

    const tokens2 = text2
      .toLowerCase()
      .replace(/[^\w\s가-힣]/g, " ")
      .split(/\s+/)
      .filter((t) => t.length > 0);

    if (tokens1.length < n || tokens2.length < n) {
      return 0;
    }

    const ngrams1 = new Set<string>();
    const ngrams2 = new Set<string>();

    for (let i = 0; i <= tokens1.length - n; i++) {
      ngrams1.add(tokens1.slice(i, i + n).join(" "));
    }

    for (let i = 0; i <= tokens2.length - n; i++) {
      ngrams2.add(tokens2.slice(i, i + n).join(" "));
    }

    const intersection = new Set(
      [...ngrams1].filter((ngram) => ngrams2.has(ngram)),
    );
    const union = new Set([...ngrams1, ...ngrams2]);

    return union.size > 0 ? intersection.size / union.size : 0;
  }

  private calculateCosineSimilarity(text1: string, text2: string): number {
    // 기존 evidenceQuality.ts의 calculateCosineSimilarity 이관
    const chars1 = new Map<string, number>();
    const chars2 = new Map<string, number>();

    for (const char of text1.toLowerCase()) {
      if (/[\w가-힣]/.test(char)) {
        chars1.set(char, (chars1.get(char) || 0) + 1);
      }
    }

    for (const char of text2.toLowerCase()) {
      if (/[\w가-힣]/.test(char)) {
        chars2.set(char, (chars2.get(char) || 0) + 1);
      }
    }

    const allChars = new Set([...chars1.keys(), ...chars2.keys()]);
    let dotProduct = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (const char of allChars) {
      const freq1 = chars1.get(char) || 0;
      const freq2 = chars2.get(char) || 0;

      dotProduct += freq1 * freq2;
      norm1 += freq1 * freq1;
      norm2 += freq2 * freq2;
    }

    if (norm1 === 0 || norm2 === 0) return 0;

    return dotProduct / Math.sqrt(norm1 * norm2);
  }
}
```

#### D. LLM Aligner (의미 기반, 향후 구현)

```typescript
// src/domain/alignment/llm-aligner.ts (신규, Phase 3)

export class LLMSemanticAligner implements SemanticAligner {
  private llm: any; // AnthropicClient
  private lexicalAligner: LexicalAligner;

  constructor(llm: any) {
    this.llm = llm;
    this.lexicalAligner = new LexicalAligner();
  }

  async calculateAlignment(
    answer: string,
    evidence: string,
  ): Promise<AlignmentResult> {
    // 1. 직접 인용 검사 (빠른 경로)
    const lexicalResult = await this.lexicalAligner.calculateAlignment(
      answer,
      evidence,
    );

    if (lexicalResult.method === "direct_quote") {
      // 직접 인용이면 LLM 호출 생략
      return lexicalResult;
    }

    // 2. LLM 기반 의미 정렬 (의역/추론 검사)
    const prompt = `
다음 두 문장의 의미 정렬을 평가하세요:

Evidence: "${evidence}"
Answer: "${answer}"

평가 기준:
1. 답변이 Evidence를 직접 인용하는가? (direct_quote)
2. 답변이 Evidence를 의역했는가? (paraphrase)
3. 답변이 Evidence에서 추론 가능한가? (inference)
4. 답변과 Evidence가 관련 없는가? (unrelated)

JSON 형식으로 응답:
{
  "method": "direct_quote | paraphrase | inference | unrelated",
  "score": 0.0 ~ 1.0,
  "reasoning": "설명"
}`;

    const response = await this.llm.complete(prompt);
    const result = JSON.parse(response);

    return {
      score: result.score,
      method: result.method,
      confidence: 0.9,
      matchedSpans: [],
    };
  }
}
```

### 3.3 Question Classification (domain/classification/)

#### A. Question Classifier 인터페이스

```typescript
// src/domain/classification/question-classifier.ts (신규)

export type QuestionType =
  | "analytical"
  | "procedural"
  | "comparative"
  | "factual";

export interface QuestionClassifier {
  classify(question: string): QuestionType;
  classifyWithConfidence(question: string): {
    type: QuestionType;
    confidence: number;
  };
}
```

#### B. Pattern Classifier (기존 정규식 기반)

```typescript
// src/domain/classification/pattern-classifier.ts (신규, 기존 코드 이관)

export class PatternClassifier implements QuestionClassifier {
  private patterns = {
    analytical: /왜|이유|원인|까닭/,
    procedural: /어떻게|방법|과정|절차/,
    comparative: /차이|비교|다른|유사|같은/,
    factual: /무엇|누가|언제|어디/,
  };

  classify(question: string): QuestionType {
    const q = question.toLowerCase();

    // 우선순위: analytical > procedural > comparative > factual
    if (this.patterns.analytical.test(q)) return "analytical";
    if (this.patterns.procedural.test(q)) return "procedural";
    if (this.patterns.comparative.test(q)) return "comparative";
    if (this.patterns.factual.test(q)) return "factual";

    return "factual"; // 기본값
  }

  classifyWithConfidence(question: string): {
    type: QuestionType;
    confidence: number;
  } {
    const type = this.classify(question);

    // 신뢰도 계산 (패턴 매칭 강도)
    const q = question.toLowerCase();
    const pattern = this.patterns[type];
    const matches = q.match(pattern);

    const confidence = matches ? 0.8 : 0.5; // 매칭되면 0.8, 기본값이면 0.5

    return { type, confidence };
  }
}
```

---

## 4. 마이그레이션 전략

### 4.1 단계별 마이그레이션

#### Phase 1: Domain 계층 구축 (2-3시간)

**작업 내용**:

1. `src/domain/` 폴더 생성
2. Entity Extraction 모듈 구현
   - `entity-recognizer.ts` (인터페이스)
   - `korean-ner.ts` (NER)
   - `entity-dictionary.ts` (도메인 사전)
   - `composite-extractor.ts` (결합)
3. Evidence Alignment 모듈 구현
   - `semantic-aligner.ts` (인터페이스)
   - `citation-detector.ts` (직접 인용 검출)
   - `lexical-aligner.ts` (기존 코드 이관)
4. Question Classification 모듈 구현
   - `question-classifier.ts` (인터페이스)
   - `pattern-classifier.ts` (기존 코드 이관)

**테스트**:

```bash
# 단위 테스트
npm run test tests/domain/extraction/
npm run test tests/domain/alignment/
npm run test tests/domain/classification/

# 타입 체크
npm run typecheck
```

#### Phase 2: Diversity Planner Agent 생성 (1-2시간)

**작업 내용**:

1. `src/agents/diversityPlanner.ts` 생성
2. Domain 모듈 통합
3. 품질 목표 설정 로직 구현
4. 생성 계획 수립 로직 구현

**테스트**:

```bash
npm run test tests/agents/diversityPlanner.test.ts
```

#### Phase 3: Metrics 리팩토링 (1-2시간)

**작업 내용**:

1. `coverageMetrics.ts` 개선
   - CompositeExtractor 사용
   - 기존 extractKeyPhrases 제거
2. `evidenceQuality.ts` 개선
   - LexicalAligner 사용
   - 기존 calculateSnippetAlignment 제거
3. `qtypeDistribution.ts` 개선
   - PatternClassifier 사용

**테스트**:

```bash
npm run test tests/quality/

# 회귀 테스트
npm run baseline:generate -- --input test-data/sample.json --output test-results/baseline.json
```

#### Phase 4: 피드백 루프 구축 (2-3시간)

**작업 내용**:

1. `QAGenerator` 개선
   - `generateQAWithFeedback` 메서드 추가
   - `regenerateWithFeedback` 메서드 추가
2. Orchestrator 통합
   - Diversity Planner 호출
   - 피드백 루프 연결
3. 로깅 및 모니터링
   - Regeneration 횟수 추적
   - 품질 개선 메트릭

**테스트**:

```bash
npm run test tests/integration/feedback-loop.test.ts
npm run dev -- --qa-count 100
```

#### Phase 5: 통합 테스트 및 배포 (1시간)

**작업 내용**:

1. 전체 시스템 통합 테스트
2. 100개 샘플 생성 및 메트릭 비교
3. 문서 업데이트
4. 배포

**테스트**:

```bash
npm run typecheck
npm run lint
npm run test
npm run ci:quality

# Baseline 비교
npm run baseline:compare -- --before baseline-before.json --after baseline-after.json
```

### 4.2 하위 호환성 보장

**원칙**:

1. **기존 API 유지**: 외부 인터페이스 변경 없음
2. **Feature Flag**: `ENABLE_ENHANCED_METRICS=true/false`
3. **Fallback**: 신규 모듈 실패 시 기존 로직 사용

**구현 예시**:

```typescript
// src/scripts/metrics/coverageMetrics.ts (개선)

import { CompositeExtractor } from "../../domain/extraction/composite-extractor.js";

const ENABLE_ENHANCED_METRICS = process.env.ENABLE_ENHANCED_METRICS === "true";

export function calculateCoverageMetrics(
  qaItems: QAItem[],
  sourceTexts: string[],
  config: CoverageConfig,
): CoverageMetrics {
  if (ENABLE_ENHANCED_METRICS) {
    // ✅ 신규 로직 (domain 모듈 사용)
    return calculateEnhancedCoverage(qaItems, sourceTexts, config);
  } else {
    // ✅ 기존 로직 (하위 호환)
    return calculateLegacyCoverage(qaItems, sourceTexts, config);
  }
}

function calculateEnhancedCoverage(
  qaItems: QAItem[],
  sourceTexts: string[],
  config: CoverageConfig,
): CoverageMetrics {
  const extractor = new CompositeExtractor();
  // ... domain 모듈 사용
}

function calculateLegacyCoverage(
  qaItems: QAItem[],
  sourceTexts: string[],
  config: CoverageConfig,
): CoverageMetrics {
  // 기존 extractKeyPhrases 사용
  // ... 기존 로직
}
```

### 4.3 롤백 계획

**조건**:

- 타입 체크 실패 시
- 테스트 실패율 > 10% 시
- 메트릭 저하 > 10% 시

**롤백 절차**:

```bash
# 1. Feature Flag OFF
export ENABLE_ENHANCED_METRICS=false

# 2. Git revert (최후 수단)
git revert HEAD~5..HEAD

# 3. 빌드 및 테스트
npm run build
npm run test
```

---

## 5. 예상 효과

### 5.1 메트릭 개선

| 지표                   | 현재         | 목표       | 개선 방법                    |
| ---------------------- | ------------ | ---------- | ---------------------------- |
| **엔티티 커버리지**    | 46.7%        | 85%+       | NER + 도메인 사전            |
| **Evidence Alignment** | ~46%         | 85%+       | 직접 인용 강화 + 피드백 루프 |
| **질문 유형 분류**     | ✅ 수정 완료 | 4가지 균형 | Agent 연동                   |

### 5.2 품질 향상

**Before (Phase 1)**:

```json
{
  "entity_coverage_rate": 0.467,
  "alignment_score": 0.269,
  "classified_type": "factual"
}
```

**After (Phase 2)**:

```json
{
  "entity_coverage_rate": 0.87, // ⬆ 86% 증가
  "alignment_score": 0.89, // ⬆ 231% 증가
  "classified_type": "analytical",
  "confidence": 0.8,
  "regeneration_count": 1 // 피드백 루프 작동
}
```

### 5.3 아키텍처 개선

**Before**:

- 분산된 책임 (agents/metrics/tools)
- 피드백 루프 부재
- 규칙 기반 (NER 없음, 문자 유사도)

**After**:

- 명확한 계층 (domain/agents/metrics)
- 피드백 루프 구축
- LLM 활용 강화 (NER + 의미 정렬)

---

## 6. 리스크 및 완화

### 6.1 리스크

| 리스크               | 확률 | 영향도 | 완화 전략                          |
| -------------------- | ---- | ------ | ---------------------------------- |
| **타입 안정성 저하** | 중   | 높음   | 단계별 타입 체크 + pre-commit hook |
| **성능 저하**        | 중   | 중     | 벤치마크 + Feature Flag + Fallback |
| **메트릭 저하**      | 낮   | 높음   | Baseline 비교 + 롤백 계획          |
| **구현 지연**        | 중   | 중     | 단계별 마일스톤 + 우선순위 조정    |

### 6.2 완화 전략

#### A. 타입 안정성

```bash
# 각 단계마다 타입 체크
npm run typecheck

# pre-commit hook 활용
npm run ci:quality
```

#### B. 성능 모니터링

```typescript
// 성능 벤치마크
import { performance } from "perf_hooks";

const start = performance.now();
const result = await extractor.extractEntities(texts);
const duration = performance.now() - start;

if (duration > 1000) {
  console.warn(`Performance degradation: ${duration}ms`);
}
```

#### C. 메트릭 비교

```bash
# Before baseline 생성
npm run baseline:generate -- --output baseline-before.json

# 개선 후 baseline 생성
npm run baseline:generate -- --output baseline-after.json

# 비교
npm run baseline:compare -- --before baseline-before.json --after baseline-after.json
```

---

## 7. 다음 단계 (Action Items)

### 즉시 (오늘)

- [ ] **RFC 검토 및 승인** (Architecture Team)
- [ ] **Phase 1 시작**: Domain 계층 구축
  - [ ] `src/domain/` 폴더 생성
  - [ ] Entity Extraction 모듈 구현
  - [ ] Evidence Alignment 모듈 구현
  - [ ] Question Classification 모듈 구현
  - [ ] 단위 테스트 작성

### 단기 (내일)

- [ ] **Phase 2**: Diversity Planner Agent 생성
- [ ] **Phase 3**: Metrics 리팩토링
- [ ] **Phase 4**: 피드백 루프 구축
- [ ] **Phase 5**: 통합 테스트 및 배포

### 중기 (향후)

- [ ] **LLM Aligner 구현** (Phase 3)
- [ ] **임베딩 활용** (Vector similarity)
- [ ] **도메인 사전 확장** (다른 도메인 추가)
- [ ] **자동 피드백 루프 최적화** (재시도 횟수 동적 조정)

---

## 8. 참고 문서

- `docs/fixes/P2_DESIGN_ANALYSIS_2025-10-07.md` (설계 분석)
- `docs/fixes/P2_PHASE1_COMPLETE_2025-10-07.md` (Phase 1 완료 보고서)
- `docs/P2_QUALITY_IMPROVEMENT_PLAN.md` (기존 계획)
- `src/scripts/metrics/coverageMetrics.ts` (현재 구현)
- `src/scripts/metrics/evidenceQuality.ts` (현재 구현)
- `src/scripts/metrics/qtypeDistribution.ts` (현재 구현)

---

**승인 서명**:

- [ ] Architecture Team
- [ ] QA Team
- [ ] DevOps Team

**예상 완료일**: 2025-10-08 (2일)
**리스크 수준**: 🟡 Medium (Feature Flag + Fallback으로 완화)
