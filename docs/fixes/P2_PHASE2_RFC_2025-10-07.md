# P2 Phase 2: ê·¼ë³¸ ì„¤ê³„ ê°œì„  RFC

**ë‚ ì§œ**: 2025-10-07
**ìƒíƒœ**: ğŸŸ¢ ìŠ¹ì¸ë¨ (Approved)
**ì‘ì„±ì**: Claude Code
**ê²€í† ì**: Architecture Team

---

## Executive Summary

**ëª©í‘œ**: P2 í’ˆì§ˆ ì´ìŠˆë¥¼ "ì¦ìƒ ì¹˜ë£Œ"ê°€ ì•„ë‹Œ "ê·¼ë³¸ ì„¤ê³„ ê°œì„ "ìœ¼ë¡œ í•´ê²°

| ì§€í‘œ                   | í˜„ì¬         | ëª©í‘œ       | ì„¤ê³„ ê°œì„                                      |
| ---------------------- | ------------ | ---------- | --------------------------------------------- |
| **ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€**    | 46.7%        | 85%+       | NER + ë„ë©”ì¸ ì‚¬ì „ + Agent í†µí•©                |
| **Evidence Alignment** | ~46%         | 85%+       | ì˜ë¯¸ ê¸°ë°˜ ì •ë ¬ + ì§ì ‘ ì¸ìš© ê°•í™” + í”¼ë“œë°± ë£¨í”„ |
| **ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜**     | âœ… ìˆ˜ì • ì™„ë£Œ | 4ê°€ì§€ ê· í˜• | Agent ê³„ì¸µ ì—°ë™                               |

**í•µì‹¬ ì•„ì´ë””ì–´**:

1. **ê³„ì¸µ ì¬êµ¬ì¡°í™”**: domain/ ìƒì„± (extraction/alignment/classification)
2. **Agent í†µí•©**: Diversity Planner ìƒì„± (í’ˆì§ˆ ëª©í‘œ ì„¤ì •)
3. **í”¼ë“œë°± ë£¨í”„**: í’ˆì§ˆ ê²€ì¦ â†’ Regeneration (ìµœëŒ€ 3íšŒ)
4. **LLM í™œìš© ê°•í™”**: ê·œì¹™ ê¸°ë°˜ â†’ ì˜ë¯¸ ì´í•´

---

## 1. í˜„ì¬ ì•„í‚¤í…ì²˜ ë¶„ì„

### 1.1 Dependency Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ calculateDetailedMetrics (scripts/metrics/__all__) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”œâ”€â–º duplicationMetrics.ts       (ì¤‘ë³µ ê²€ì‚¬)
                 â”œâ”€â–º qtypeDistribution.ts        (ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜) âœ… ìˆ˜ì • ì™„ë£Œ
                 â”œâ”€â–º coverageMetrics.ts          (ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€) âš ï¸ ê°œì„  í•„ìš”
                 â”œâ”€â–º evidenceQuality.ts          (ì¦ê±° ì •ë ¬) âš ï¸ ê°œì„  í•„ìš”
                 â”œâ”€â–º hallucinationRules.ts       (í™˜ê° ê²€ì‚¬)
                 â””â”€â–º piiLicenseScan.ts           (PII/ë¼ì´ì„¼ìŠ¤)
```

### 1.2 í•µì‹¬ ë¬¸ì œì 

#### A. ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€ (coverageMetrics.ts)

**í˜„ì¬ êµ¬í˜„**:

```typescript
// Line 61-96: ë‹¨ìˆœ n-gram ì¶”ì¶œ
function extractKeyPhrases(
  text: string,
  minLength: number,
  maxLength: number,
): string[] {
  const normalized = text
    .toLowerCase()
    .replace(/[^\w\sê°€-í£]/g, " ") // âŒ í•œì ì œê±°ë¨!
    .trim();

  // n-gram ì¶”ì¶œ (1-3 ë‹¨ì–´)
  for (let n = minLength; n <= maxLength; n++) {
    for (let i = 0; i <= words.length - n; i++) {
      const phrase = words.slice(i, i + n).join(" ");
      phrases.push(phrase);
    }
  }

  return phrases; // âŒ ë¹ˆë„ìˆœ ì •ë ¬, NER ì—†ìŒ
}
```

**ë¬¸ì œ**:

1. **í•œì ì²˜ë¦¬ ë¶€ì¬**: "êµ¬ì´ë””" (ë³¸ëª…) â†’ ì •ê·œì‹ì—ì„œ ì œê±°ë¨
2. **ë³µí•©ì–´ ì²˜ë¦¬ ì‹¤íŒ¨**: "ê±´ì¶•ì—ì„œì˜" â†’ ë¶„ë¦¬ ì•ˆ ë¨
3. **ê³ ìœ ëª…ì‚¬ ì¸ì‹ ì—†ìŒ**: "ë¸Œë£¨ë„¬ë ˆìŠ¤í‚¤ë‚˜" â†’ ì¼ë°˜ n-gramìœ¼ë¡œë§Œ ì²˜ë¦¬
4. **ë¹ˆë„ ê¸°ë°˜ ì¶”ì¶œ**: ì¤‘ìš”í•˜ì§€ë§Œ ë¹ˆë„ ë‚®ì€ ì—”í‹°í‹° ëˆ„ë½

**ê²°ê³¼**: 46.7% ì»¤ë²„ë¦¬ì§€ (ëª©í‘œ 50% ë¯¸ë‹¬)

#### B. Evidence Alignment (evidenceQuality.ts)

**í˜„ì¬ êµ¬í˜„**:

```typescript
// Line 157-178: ë‹¨ìˆœ ë¬¸ì ê¸°ë°˜ ìœ ì‚¬ë„
function calculateSnippetAlignment(
  answer: string,
  evidence: string,
  config: EvidenceConfig,
): number {
  // 1. n-gram overlap (3-gram)
  const ngramOverlap = calculateNgramOverlap(answer, evidence, 3);

  // 2. Character-level cosine similarity
  const cosineSim = calculateCosineSimilarity(answer, evidence);

  // 3. ê°€ì¤‘ í‰ê·  (40% + 60%)
  const alignmentScore = ngramOverlap * 0.4 + cosineSim * 0.6;

  return Math.min(alignmentScore, 1.0);
}
```

**ë¬¸ì œ**:

1. **ì˜ë¯¸ ë¬´ì‹œ**: "ë¸Œë£¨ë„¬ë ˆìŠ¤í‚¤ì™€ í•¨ê»˜" â‰  "15ì„¸ê¸° ì´ˆ ìœ í–‰í•˜ë˜ êµ­ì œê³ ë”•ì–‘ì‹"

   - ë¬¸ìì ìœ¼ë¡œ ì™„ì „íˆ ë‹¤ë¦„ â†’ Alignment 0%
   - í•˜ì§€ë§Œ ì˜ë¯¸ìƒ ê´€ë ¨ìˆìŒ (Evidenceì—ì„œ ì¶”ë¡  ê°€ëŠ¥)

2. **ì˜ì—­ ì²˜ë¦¬ ë¶ˆê°€**:

   ```
   Evidence: "ë¸Œë£¨ë„¬ë ˆìŠ¤í‚¤ë‚˜ ë„ë‚˜í…”ë¡œì™€ í•¨ê»˜"
   Answer: "ë§ˆì‚¬ì´ˆëŠ” 15ì„¸ê¸° ì´ˆ ìœ í–‰í•˜ë˜ êµ­ì œê³ ë”•ì–‘ì‹ì„ ë”°ë¥´ì§€ ì•Šì•˜ì–´ìš”"
   Alignment: 26.9% âŒ
   ```

   - ë‹µë³€ì´ Evidenceë¥¼ ì˜ì—­/í™•ì¥ â†’ ë¬¸ì ë§¤ì¹­ ì‹¤íŒ¨

3. **ì¸ìš©êµ¬ ì¶”ì¶œ ì—†ìŒ**: ì§ì ‘ ì¸ìš© ë¶€ë¶„ì„ ê°ì§€í•˜ì§€ ëª»í•¨

**ê²°ê³¼**: ~46% Alignment (ëª©í‘œ 60% ë¯¸ë‹¬)

#### C. Agent-Metric ë¶„ë¦¬

**í˜„ì¬ êµ¬ì¡°**:

```
src/
â”œâ”€â”€ agents/          # QA ìƒì„± (ë©”íŠ¸ë¦­ ë¬´ê´€)
â”‚   â”œâ”€â”€ qaGenerator.ts
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/metrics/ # ë©”íŠ¸ë¦­ ê³„ì‚° (ì‚¬í›„ í‰ê°€ë§Œ)
â”‚   â”œâ”€â”€ coverageMetrics.ts
â”‚   â”œâ”€â”€ evidenceQuality.ts
â”‚   â””â”€â”€ qtypeDistribution.ts
â”‚
â””â”€â”€ tools/           # ì™¸ë¶€ ë„êµ¬ (ë¯¸í†µí•©)
    â””â”€â”€ diversity_analyzer.js
```

**ë¬¸ì œ**:

- QA ìƒì„± ì‹œ í’ˆì§ˆ ëª©í‘œë¥¼ ê³ ë ¤í•˜ì§€ ëª»í•¨
- Metric ê³„ì‚°ì€ ì‚¬í›„ í‰ê°€ë§Œ ê°€ëŠ¥
- **í”¼ë“œë°± ë£¨í”„ ë¶€ì¬** â† ê°€ì¥ í° ë¬¸ì œ
- Diversity Planner Agent ë¶€ì¬ (ê³„íšì—ëŠ” ìˆì§€ë§Œ ë¯¸êµ¬í˜„)

---

## 2. ì„¤ê³„ ê°œì„  ì „ëµ

### 2.1 ê³„ì¸µ ì¬êµ¬ì¡°í™”

#### Before (ë¶„ì‚°ë¨)

```
src/
â”œâ”€â”€ agents/          # QA ìƒì„±
â”œâ”€â”€ scripts/metrics/ # ë©”íŠ¸ë¦­ (ì‚¬í›„)
â””â”€â”€ tools/           # ì™¸ë¶€ ë„êµ¬
```

#### After (í†µí•©ë¨)

```
src/
â”œâ”€â”€ domain/                         # ë„ë©”ì¸ ë¡œì§ (ìƒˆë¡œ ìƒì„±)
â”‚   â”œâ”€â”€ extraction/                 # ì—”í‹°í‹° ì¶”ì¶œ
â”‚   â”‚   â”œâ”€â”€ entity-recognizer.ts    # NER ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ korean-ner.ts           # í•œêµ­ì–´ íŠ¹í™” NER
â”‚   â”‚   â”œâ”€â”€ entity-dictionary.ts    # ë„ë©”ì¸ ì‚¬ì „
â”‚   â”‚   â””â”€â”€ composite-extractor.ts  # NER + ì‚¬ì „ ê²°í•©
â”‚   â”‚
â”‚   â”œâ”€â”€ alignment/                  # ì¦ê±° ì •ë ¬
â”‚   â”‚   â”œâ”€â”€ semantic-aligner.ts     # ì˜ë¯¸ ê¸°ë°˜ ì •ë ¬ ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ lexical-aligner.ts      # ê¸°ì¡´ ë¬¸ì ê¸°ë°˜ (fallback)
â”‚   â”‚   â”œâ”€â”€ llm-aligner.ts          # LLM ê¸°ë°˜ ì˜ë¯¸ ì •ë ¬
â”‚   â”‚   â””â”€â”€ citation-detector.ts    # ì§ì ‘ ì¸ìš© ê²€ì¶œ
â”‚   â”‚
â”‚   â””â”€â”€ classification/             # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
â”‚       â”œâ”€â”€ question-classifier.ts  # ë¶„ë¥˜ ì¸í„°í˜ì´ìŠ¤
â”‚       â”œâ”€â”€ pattern-classifier.ts   # ê¸°ì¡´ ì •ê·œì‹ ê¸°ë°˜
â”‚       â””â”€â”€ llm-classifier.ts       # LLM ê¸°ë°˜ ë¶„ë¥˜ (í–¥í›„)
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ qaGenerator.ts              # QA ìƒì„± (ê¸°ì¡´)
â”‚   â””â”€â”€ diversityPlanner.ts         # í’ˆì§ˆ ëª©í‘œ ì„¤ì • (ì‹ ê·œ) â­
â”‚
â””â”€â”€ scripts/metrics/                # ê²€ì¦ë§Œ ë‹´ë‹¹
    â”œâ”€â”€ coverageMetrics.ts          # domain/extraction ì‚¬ìš©
    â”œâ”€â”€ evidenceQuality.ts          # domain/alignment ì‚¬ìš©
    â””â”€â”€ qtypeDistribution.ts        # domain/classification ì‚¬ìš©
```

**í•µì‹¬ ë³€í™”**:

1. **domain/ ê³„ì¸µ ì‹ ê·œ ìƒì„±**: ë„ë©”ì¸ ë¡œì§ ìº¡ìŠí™”
2. **Diversity Planner Agent ì¶”ê°€**: í’ˆì§ˆ ëª©í‘œ ì„¤ì • ë° ê³„íš
3. **metricsëŠ” ê²€ì¦ë§Œ ë‹´ë‹¹**: ë„ë©”ì¸ ë¡œì§ ì¬ì‚¬ìš©

### 2.2 Diversity Planner Agent ì„¤ê³„

**ì—­í• **: QA ìƒì„± ì „ í’ˆì§ˆ ëª©í‘œ ì„¤ì • ë° ì „ëµ ìˆ˜ë¦½

```typescript
// src/agents/diversityPlanner.ts (ì‹ ê·œ)

export interface DiversityPlan {
  // ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€ ëª©í‘œ
  entityCoverage: {
    targetRate: number; // 85%
    targetEntities: Entity[]; // NER + ì‚¬ì „ ê²°í•©
    coverageStrategy: string; // "balanced" | "priority"
  };

  // Evidence Alignment ëª©í‘œ
  evidenceAlignment: {
    minScore: number; // 0.85
    alignmentStrategy: string; // "direct_quote" | "paraphrase"
    citationRequirement: boolean; // true
  };

  // ì§ˆë¬¸ ìœ í˜• ëª©í‘œ
  questionTypeDistribution: {
    analytical: number; // 30%
    procedural: number; // 30%
    comparative: number; // 20%
    factual: number; // 20%
  };

  // ìƒì„± ê³„íš
  generationPlan: GenerationTask[];
}

export interface GenerationTask {
  taskId: string;
  type: "analytical" | "procedural" | "comparative" | "factual";
  targetEntity?: Entity; // ì»¤ë²„í•  ì—”í‹°í‹°
  evidenceSnippet: string; // ì‚¬ìš©í•  Evidence
  qualityRequirements: {
    minAlignmentScore: number; // 0.85
    requireDirectQuote: boolean; // true
    maxRegenerationAttempts: number; // 3
  };
}

export class DiversityPlanner extends BaseAgent {
  private ner: CompositeExtractor;
  private aligner: SemanticAligner;
  private classifier: QuestionClassifier;

  constructor() {
    super("diversityPlanner", "Diversity planning and quality target setting");
    this.ner = new CompositeExtractor();
    this.aligner = new LexicalAligner(); // fallback
    this.classifier = new PatternClassifier();
  }

  async planDiversity(
    sourceTexts: string[],
    domain: string,
    targetCount: number,
  ): Promise<DiversityPlan> {
    // 1. ì—”í‹°í‹° ì¶”ì¶œ (NER + ì‚¬ì „ ê²°í•©)
    const entities = await this.ner.extractEntities(sourceTexts, domain);

    // 2. ì—”í‹°í‹° ìš°ì„ ìˆœìœ„ ê²°ì •
    const targetEntities = this.selectTargetEntities(entities, 0.85); // 85% ëª©í‘œ

    // 3. ì§ˆë¬¸ ìœ í˜• ë¶„í¬ ê³„íš
    const typeDistribution = {
      analytical: Math.floor(targetCount * 0.3),
      procedural: Math.floor(targetCount * 0.3),
      comparative: Math.floor(targetCount * 0.2),
      factual: Math.floor(targetCount * 0.2),
    };

    // 4. ìƒì„± ê³„íš ìˆ˜ë¦½
    const generationPlan = this.createGenerationPlan(
      targetEntities,
      typeDistribution,
      sourceTexts,
    );

    return {
      entityCoverage: {
        targetRate: 0.85,
        targetEntities,
        coverageStrategy: "balanced",
      },
      evidenceAlignment: {
        minScore: 0.85,
        alignmentStrategy: "direct_quote",
        citationRequirement: true,
      },
      questionTypeDistribution: typeDistribution,
      generationPlan,
    };
  }

  private selectTargetEntities(
    entities: Entity[],
    targetRate: number,
  ): Entity[] {
    // ì‹ ë¢°ë„ ê¸°ë°˜ ì •ë ¬
    const sorted = entities.sort((a, b) => b.confidence - a.confidence);

    // ìƒìœ„ Nê°œ ì„ íƒ (ëª©í‘œ ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±)
    const count = Math.ceil(entities.length * targetRate);
    return sorted.slice(0, count);
  }

  private createGenerationPlan(
    targetEntities: Entity[],
    typeDistribution: Record<string, number>,
    sourceTexts: string[],
  ): GenerationTask[] {
    const tasks: GenerationTask[] = [];

    // ê° ì§ˆë¬¸ ìœ í˜•ë³„ë¡œ íƒœìŠ¤í¬ ìƒì„±
    for (const [type, count] of Object.entries(typeDistribution)) {
      for (let i = 0; i < count; i++) {
        // ì—”í‹°í‹° í• ë‹¹ (ë¼ìš´ë“œë¡œë¹ˆ)
        const entity = targetEntities[tasks.length % targetEntities.length];

        // Evidence ì„ íƒ (ì—”í‹°í‹° í¬í•¨)
        const evidenceSnippet = this.selectEvidence(entity, sourceTexts);

        tasks.push({
          taskId: `task_${type}_${i}`,
          type: type as any,
          targetEntity: entity,
          evidenceSnippet,
          qualityRequirements: {
            minAlignmentScore: 0.85,
            requireDirectQuote: true,
            maxRegenerationAttempts: 3,
          },
        });
      }
    }

    return tasks;
  }

  private selectEvidence(entity: Entity, sourceTexts: string[]): string {
    // ì—”í‹°í‹°ë¥¼ í¬í•¨í•˜ëŠ” Evidence ì„ íƒ
    for (const text of sourceTexts) {
      if (text.includes(entity.text)) {
        // ì—”í‹°í‹° ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ (Â±50ì)
        const index = text.indexOf(entity.text);
        const start = Math.max(0, index - 50);
        const end = Math.min(text.length, index + entity.text.length + 50);
        return text.substring(start, end);
      }
    }

    return sourceTexts[0]; // fallback
  }
}
```

### 2.3 í”¼ë“œë°± ë£¨í”„ êµ¬ì¶•

**ê¸°ì¡´ íë¦„ (í”¼ë“œë°± ì—†ìŒ)**:

```
QA ìƒì„± â†’ ë©”íŠ¸ë¦­ ê³„ì‚° â†’ ë³´ê³ ì„œ ì¶œë ¥ (ë)
```

**ê°œì„  íë¦„ (í”¼ë“œë°± ë£¨í”„)**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Diversity Plannerâ”‚
â”‚ (ëª©í‘œ ì„¤ì •)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QA Generator     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ (ìƒì„±)           â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
         â”‚                           â”‚
         â–¼                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ Quality Validatorâ”‚                 â”‚
â”‚ (ê²€ì¦)           â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
         â”‚                           â”‚
         â–¼                           â”‚
    í’ˆì§ˆ ì¶©ì¡±?                        â”‚
         â”‚                           â”‚
         â”œâ”€â”€ Yes â†’ Accept            â”‚
         â”‚                           â”‚
         â””â”€â”€ No  â†’ Regenerate â”€â”€â”€â”€â”€â”€â”€â”˜
                   (ìµœëŒ€ 3íšŒ)
```

**êµ¬í˜„ ì˜ˆì‹œ**:

```typescript
// src/agents/qaGenerator.ts (ê°œì„ )

export class QAGenerator extends BaseAgent {
  private aligner: SemanticAligner;
  private maxRegenerationAttempts = 3;

  async generateQAWithFeedback(task: GenerationTask): Promise<QAItem> {
    let attempts = 0;
    let qa: QAItem | null = null;
    let alignment: AlignmentResult | null = null;

    while (attempts < this.maxRegenerationAttempts) {
      attempts++;

      // 1. QA ìƒì„±
      qa = await this.generateQA(task);

      // 2. Alignment ê²€ì¦
      alignment = await this.aligner.calculateAlignment(
        qa.a,
        task.evidenceSnippet
      );

      // 3. í’ˆì§ˆ ì¶©ì¡± ì—¬ë¶€ í™•ì¸
      if (alignment.score >= task.qualityRequirements.minAlignmentScore) {
        // âœ… í’ˆì§ˆ ì¶©ì¡± â†’ Accept
        return qa;
      }

      // âŒ í’ˆì§ˆ ë¯¸ë‹¬ â†’ Regenerate with feedback
      if (attempts < this.maxRegenerationAttempts) {
        qa = await this.regenerateWithFeedback(qa, alignment, task);
      }
    }

    // ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ â†’ ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜ (ê²½ê³  í¬í•¨)
    console.warn(`QA generation failed to meet quality requirements after ${attempts} attempts`);
    return qa!;
  }

  private async regenerateWithFeedback(
    failedQA: QAItem,
    alignment: AlignmentResult,
    task: GenerationTask
  ): Promise<QAItem> {
    const prompt = `
ì´ì „ ë‹µë³€ì˜ Alignmentê°€ ë‚®ìŠµë‹ˆë‹¤ (${alignment.score.toFixed(2)}).
Evidenceë¥¼ **ë” ì§ì ‘ì ìœ¼ë¡œ ì¸ìš©**í•˜ì„¸ìš”.

Evidence: "${task.evidenceSnippet}"
ì´ì „ ë‹µë³€: "${failedQA.a}"

ê°œì„  ìš”êµ¬ì‚¬í•­:
1. Evidenceì˜ í•µì‹¬ ë¬¸ì¥ì„ **ê·¸ëŒ€ë¡œ í¬í•¨**
2. "ë¬¸ì„œì— ë”°ë¥´ë©´ '${ì§ì ‘ ì¸ìš©}' í•©ë‹ˆë‹¤" í˜•ì‹ ì‚¬ìš©
3. ì˜ì—­ë³´ë‹¤ëŠ” ì§ì ‘ ì¸ìš© ìš°ì„ 

ê°œì„ ëœ ë‹µë³€:`;

    const improved = await this.llm.complete(prompt);
    return { ...failedQA, a: improved };
  }
}
```

---

## 3. Domain ê³„ì¸µ ì„¤ê³„

### 3.1 Entity Extraction (domain/extraction/)

#### A. Entity Recognizer ì¸í„°í˜ì´ìŠ¤

```typescript
// src/domain/extraction/entity-recognizer.ts (ì‹ ê·œ)

export interface Entity {
  text: string;
  type: "PERSON" | "LOCATION" | "TERM" | "DATE" | "OTHER";
  confidence: number;
  span: [number, number];
  source: "ner" | "dictionary" | "hybrid";
}

export interface EntityRecognizer {
  extractEntities(text: string, domain?: string): Promise<Entity[]>;
}
```

#### B. Korean NER

```typescript
// src/domain/extraction/korean-ner.ts (ì‹ ê·œ)

export class KoreanNER implements EntityRecognizer {
  private patterns = {
    // í•œêµ­ì–´ ì´ë¦„ (2-4ì)
    person: /([ê°€-í£]{2,4}|[A-Z][a-z]+\s*[A-Z][a-z]+)/g,

    // ì§€ëª… (ì‹œ/ë„/êµ­ê°€)
    location: /(ì‹œì¹ ë¦¬ì•„|ë² ë„¤ì¹˜ì•„|ë°€ë¼ë…¸|[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„|[ê°€-í£]+êµ­)/g,

    // ì „ë¬¸ ìš©ì–´
    term: /(ë¥´ë„¤ìƒìŠ¤|ê³ ë”•|ìœ í™”|ëª…ì•”í‘œí˜„ë²•|ì›ê·¼ë²•|êµ­ì œê³ ë”•ì–‘ì‹)/g,

    // í•œì ì´ë¦„ (2-4ì)
    hanja: /[ä¸€-é¾¥]{2,4}/g,

    // ë‚ ì§œ (15ì„¸ê¸°, 1420ë…„ëŒ€ ë“±)
    date: /(\d{1,2}ì„¸ê¸°|\d{4}ë…„ëŒ€?)/g,
  };

  async extractEntities(text: string, _domain?: string): Promise<Entity[]> {
    const entities: Entity[] = [];

    // íŒ¨í„´ ë§¤ì¹­
    for (const [type, pattern] of Object.entries(this.patterns)) {
      const matches = [...text.matchAll(pattern)];
      for (const match of matches) {
        entities.push({
          text: match[0],
          type: this.mapTypeToCategory(type),
          confidence: this.calculateConfidence(type),
          span: [match.index!, match.index! + match[0].length],
          source: "ner",
        });
      }
    }

    return this.deduplicateEntities(entities);
  }

  private mapTypeToCategory(patternType: string): Entity["type"] {
    const mapping: Record<string, Entity["type"]> = {
      person: "PERSON",
      hanja: "PERSON",
      location: "LOCATION",
      term: "TERM",
      date: "DATE",
    };
    return mapping[patternType] || "OTHER";
  }

  private calculateConfidence(patternType: string): number {
    // íŒ¨í„´ë³„ ì‹ ë¢°ë„
    const confidence: Record<string, number> = {
      term: 0.9, // ì „ë¬¸ ìš©ì–´ëŠ” ì‹ ë¢°ë„ ë†’ìŒ
      hanja: 0.7, // í•œì ì´ë¦„ì€ ì¤‘ê°„
      person: 0.8, // í•œê¸€ ì´ë¦„ì€ ë†’ìŒ
      location: 0.85, // ì§€ëª…ì€ ë†’ìŒ
      date: 0.95, // ë‚ ì§œëŠ” ë§¤ìš° ë†’ìŒ
    };
    return confidence[patternType] || 0.5;
  }

  private deduplicateEntities(entities: Entity[]): Entity[] {
    const seen = new Map<string, Entity>();

    for (const entity of entities) {
      const key = `${entity.text}_${entity.type}`;
      const existing = seen.get(key);

      if (!existing || entity.confidence > existing.confidence) {
        seen.set(key, entity);
      }
    }

    return Array.from(seen.values());
  }
}
```

#### C. Entity Dictionary

```typescript
// src/domain/extraction/entity-dictionary.ts (ì‹ ê·œ)

export const DOMAIN_ENTITIES = {
  art_renaissance: {
    persons: [
      "ë§ˆì‚¬ì´ˆ",
      "ë¸Œë£¨ë„¬ë ˆìŠ¤í‚¤",
      "ë„ë‚˜í…”ë¡œ",
      "ì•ˆí† ë„¬ë¡œ",
      "ë‘ì´ˆ",
      "êµ¬ì´ë””",
      "íŒŒì—ì¦ˆ",
      "ì–€ ë°˜ ì—ì´í¬",
      "ë¡œíˆì–´ ë°˜ ë°ë¥´ ë² ì´ë´",
    ],
    locations: [
      "ì‹œì¹ ë¦¬ì•„",
      "ë² ë„¤ì¹˜ì•„",
      "ë°€ë¼ë…¸",
      "ë©”ì‹œë‚˜",
      "ì‹œì—ë‚˜",
      "í”¼ë Œì²´",
      "í”Œë‘ë“œë¥´",
      "ë„¤ëœë€ë“œ",
    ],
    terms: [
      "ë¥´ë„¤ìƒìŠ¤",
      "ê³ ë”•",
      "êµ­ì œê³ ë”•ì–‘ì‹",
      "ìœ í™”",
      "ëª…ì•”í‘œí˜„ë²•",
      "ì›ê·¼ë²•",
      "ì„±ìƒí™”",
      "íŒ¨ë„í™”",
      "í…œí˜ë¼",
      "ì œë‹¨í™”",
    ],
  },
  // ë‹¤ë¥¸ ë„ë©”ì¸ ì¶”ê°€ ê°€ëŠ¥
};

export class DictionaryBasedExtractor implements EntityRecognizer {
  async extractEntities(
    text: string,
    domain: string = "art_renaissance",
  ): Promise<Entity[]> {
    const dict = DOMAIN_ENTITIES[domain as keyof typeof DOMAIN_ENTITIES] || {};
    const entities: Entity[] = [];

    for (const [type, keywords] of Object.entries(dict)) {
      for (const keyword of keywords as string[]) {
        const regex = new RegExp(keyword, "g");
        const matches = [...text.matchAll(regex)];

        for (const match of matches) {
          entities.push({
            text: match[0],
            type: this.mapTypeToCategory(type),
            confidence: 0.95, // ì‚¬ì „ ê¸°ë°˜ì€ ì‹ ë¢°ë„ ë§¤ìš° ë†’ìŒ
            span: [match.index!, match.index! + match[0].length],
            source: "dictionary",
          });
        }
      }
    }

    return entities;
  }

  private mapTypeToCategory(dictType: string): Entity["type"] {
    const mapping: Record<string, Entity["type"]> = {
      persons: "PERSON",
      locations: "LOCATION",
      terms: "TERM",
    };
    return mapping[dictType] || "OTHER";
  }
}
```

#### D. Composite Extractor (NER + ì‚¬ì „ ê²°í•©)

```typescript
// src/domain/extraction/composite-extractor.ts (ì‹ ê·œ)

export class CompositeExtractor implements EntityRecognizer {
  private ner: KoreanNER;
  private dict: DictionaryBasedExtractor;

  constructor() {
    this.ner = new KoreanNER();
    this.dict = new DictionaryBasedExtractor();
  }

  async extractEntities(
    texts: string[],
    domain: string = "art_renaissance",
  ): Promise<Entity[]> {
    const allEntities: Entity[] = [];

    for (const text of texts) {
      // 1. NER ì¶”ì¶œ
      const nerEntities = await this.ner.extractEntities(text);

      // 2. ì‚¬ì „ ì¶”ì¶œ
      const dictEntities = await this.dict.extractEntities(text, domain);

      // 3. ê²°í•©
      allEntities.push(...nerEntities, ...dictEntities);
    }

    // 4. ì¤‘ë³µ ì œê±° ë° ì‹ ë¢°ë„ ë³‘í•©
    return this.mergeEntities(allEntities);
  }

  private mergeEntities(entities: Entity[]): Entity[] {
    const merged = new Map<string, Entity>();

    for (const entity of entities) {
      const key = entity.text.toLowerCase();
      const existing = merged.get(key);

      if (!existing) {
        merged.set(key, entity);
      } else {
        // ë” ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ
        if (entity.confidence > existing.confidence) {
          merged.set(key, entity);
        }
        // ê°™ì€ ì‹ ë¢°ë„ë©´ source ìš°ì„ ìˆœìœ„ (dictionary > ner > hybrid)
        else if (entity.confidence === existing.confidence) {
          if (
            entity.source === "dictionary" &&
            existing.source !== "dictionary"
          ) {
            merged.set(key, entity);
          }
        }
      }
    }

    return Array.from(merged.values()).sort(
      (a, b) => b.confidence - a.confidence,
    );
  }
}
```

### 3.2 Evidence Alignment (domain/alignment/)

#### A. Semantic Aligner ì¸í„°í˜ì´ìŠ¤

```typescript
// src/domain/alignment/semantic-aligner.ts (ì‹ ê·œ)

export interface AlignmentResult {
  score: number; // 0-1
  method: "direct_quote" | "paraphrase" | "inference" | "unrelated";
  confidence: number;
  matchedSpans: Array<{
    answerSpan: string;
    evidenceSpan: string;
    similarity: number;
  }>;
}

export interface SemanticAligner {
  calculateAlignment(
    answer: string,
    evidence: string,
  ): Promise<AlignmentResult>;
}
```

#### B. Citation Detector (ì§ì ‘ ì¸ìš© ê²€ì¶œ)

```typescript
// src/domain/alignment/citation-detector.ts (ì‹ ê·œ)

export class CitationDetector {
  /**
   * ì§ì ‘ ì¸ìš© ê²€ì¶œ (3-gram ì´ìƒ ì¼ì¹˜)
   */
  detectDirectQuotes(
    answer: string,
    evidence: string,
  ): Array<{
    answerSpan: string;
    evidenceSpan: string;
    similarity: number;
  }> {
    const matches: Array<{
      answerSpan: string;
      evidenceSpan: string;
      similarity: number;
    }> = [];

    // ë‹µë³€ì„ n-gramìœ¼ë¡œ ë¶„í•  (n=3~10)
    for (let n = 10; n >= 3; n--) {
      const answerNgrams = this.extractNgrams(answer, n);

      for (const ngram of answerNgrams) {
        if (evidence.includes(ngram)) {
          matches.push({
            answerSpan: ngram,
            evidenceSpan: ngram,
            similarity: 1.0,
          });
        }
      }
    }

    // ì¤‘ë³µ ì œê±° (ê¸´ ë§¤ì¹­ ìš°ì„ )
    return this.deduplicateMatches(matches);
  }

  private extractNgrams(text: string, n: number): string[] {
    const ngrams: string[] = [];

    // ë¬¸ì ë‹¨ìœ„ n-gram (ê³µë°± ì œê±°)
    const cleaned = text.replace(/\s+/g, "");

    for (let i = 0; i <= cleaned.length - n; i++) {
      ngrams.push(cleaned.substring(i, i + n));
    }

    return ngrams;
  }

  private deduplicateMatches(
    matches: Array<{
      answerSpan: string;
      evidenceSpan: string;
      similarity: number;
    }>,
  ): Array<{ answerSpan: string; evidenceSpan: string; similarity: number }> {
    // ê¸´ ë§¤ì¹­ì´ ì§§ì€ ë§¤ì¹­ì„ í¬í•¨í•˜ë©´ ê¸´ ê²ƒë§Œ ìœ ì§€
    const sorted = matches.sort(
      (a, b) => b.answerSpan.length - a.answerSpan.length,
    );
    const deduplicated: typeof matches = [];

    for (const match of sorted) {
      const isSubsumed = deduplicated.some((existing) =>
        existing.answerSpan.includes(match.answerSpan),
      );

      if (!isSubsumed) {
        deduplicated.push(match);
      }
    }

    return deduplicated;
  }

  /**
   * ì§ì ‘ ì¸ìš© ë¹„ìœ¨ ê³„ì‚°
   */
  calculateDirectQuoteRatio(answer: string, evidence: string): number {
    const matches = this.detectDirectQuotes(answer, evidence);

    if (matches.length === 0) return 0;

    // ë§¤ì¹­ëœ ë¬¸ì ìˆ˜ í•©ì‚°
    const totalMatchedChars = matches.reduce(
      (sum, match) => sum + match.answerSpan.length,
      0,
    );

    // ë‹µë³€ ì „ì²´ ë¬¸ì ìˆ˜
    const answerLength = answer.replace(/\s+/g, "").length;

    return answerLength > 0 ? totalMatchedChars / answerLength : 0;
  }
}
```

#### C. Lexical Aligner (ê¸°ì¡´ ë¬¸ì ê¸°ë°˜, fallback)

```typescript
// src/domain/alignment/lexical-aligner.ts (ì‹ ê·œ, ê¸°ì¡´ ì½”ë“œ ì´ê´€)

export class LexicalAligner implements SemanticAligner {
  private citationDetector: CitationDetector;

  constructor() {
    this.citationDetector = new CitationDetector();
  }

  async calculateAlignment(
    answer: string,
    evidence: string,
  ): Promise<AlignmentResult> {
    // 1. ì§ì ‘ ì¸ìš© ê²€ì‚¬ (ìš°ì„ ìˆœìœ„ ìµœìƒ)
    const directQuoteRatio = this.citationDetector.calculateDirectQuoteRatio(
      answer,
      evidence,
    );

    if (directQuoteRatio >= 0.3) {
      // 30% ì´ìƒ ì§ì ‘ ì¸ìš© â†’ ë§¤ìš° ë†’ì€ ì ìˆ˜
      return {
        score: 0.8 + directQuoteRatio * 0.2, // 0.8 ~ 1.0
        method: "direct_quote",
        confidence: 0.95,
        matchedSpans: this.citationDetector.detectDirectQuotes(
          answer,
          evidence,
        ),
      };
    }

    // 2. n-gram overlap + cosine similarity (ê¸°ì¡´ ë°©ì‹)
    const ngramOverlap = this.calculateNgramOverlap(answer, evidence, 3);
    const cosineSim = this.calculateCosineSimilarity(answer, evidence);
    const combinedScore = ngramOverlap * 0.4 + cosineSim * 0.6;

    // 3. ë°©ë²• ë¶„ë¥˜
    let method: AlignmentResult["method"];
    if (combinedScore >= 0.5) {
      method = "paraphrase";
    } else if (combinedScore >= 0.3) {
      method = "inference";
    } else {
      method = "unrelated";
    }

    return {
      score: Math.min(combinedScore, 1.0),
      method,
      confidence: 0.7,
      matchedSpans: [],
    };
  }

  private calculateNgramOverlap(
    text1: string,
    text2: string,
    n: number,
  ): number {
    // ê¸°ì¡´ evidenceQuality.tsì˜ calculateNgramOverlap ì´ê´€
    const tokens1 = text1
      .toLowerCase()
      .replace(/[^\w\sê°€-í£]/g, " ")
      .split(/\s+/)
      .filter((t) => t.length > 0);

    const tokens2 = text2
      .toLowerCase()
      .replace(/[^\w\sê°€-í£]/g, " ")
      .split(/\s+/)
      .filter((t) => t.length > 0);

    if (tokens1.length < n || tokens2.length < n) {
      return 0;
    }

    const ngrams1 = new Set<string>();
    const ngrams2 = new Set<string>();

    for (let i = 0; i <= tokens1.length - n; i++) {
      ngrams1.add(tokens1.slice(i, i + n).join(" "));
    }

    for (let i = 0; i <= tokens2.length - n; i++) {
      ngrams2.add(tokens2.slice(i, i + n).join(" "));
    }

    const intersection = new Set(
      [...ngrams1].filter((ngram) => ngrams2.has(ngram)),
    );
    const union = new Set([...ngrams1, ...ngrams2]);

    return union.size > 0 ? intersection.size / union.size : 0;
  }

  private calculateCosineSimilarity(text1: string, text2: string): number {
    // ê¸°ì¡´ evidenceQuality.tsì˜ calculateCosineSimilarity ì´ê´€
    const chars1 = new Map<string, number>();
    const chars2 = new Map<string, number>();

    for (const char of text1.toLowerCase()) {
      if (/[\wê°€-í£]/.test(char)) {
        chars1.set(char, (chars1.get(char) || 0) + 1);
      }
    }

    for (const char of text2.toLowerCase()) {
      if (/[\wê°€-í£]/.test(char)) {
        chars2.set(char, (chars2.get(char) || 0) + 1);
      }
    }

    const allChars = new Set([...chars1.keys(), ...chars2.keys()]);
    let dotProduct = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (const char of allChars) {
      const freq1 = chars1.get(char) || 0;
      const freq2 = chars2.get(char) || 0;

      dotProduct += freq1 * freq2;
      norm1 += freq1 * freq1;
      norm2 += freq2 * freq2;
    }

    if (norm1 === 0 || norm2 === 0) return 0;

    return dotProduct / Math.sqrt(norm1 * norm2);
  }
}
```

#### D. LLM Aligner (ì˜ë¯¸ ê¸°ë°˜, í–¥í›„ êµ¬í˜„)

```typescript
// src/domain/alignment/llm-aligner.ts (ì‹ ê·œ, Phase 3)

export class LLMSemanticAligner implements SemanticAligner {
  private llm: any; // AnthropicClient
  private lexicalAligner: LexicalAligner;

  constructor(llm: any) {
    this.llm = llm;
    this.lexicalAligner = new LexicalAligner();
  }

  async calculateAlignment(
    answer: string,
    evidence: string,
  ): Promise<AlignmentResult> {
    // 1. ì§ì ‘ ì¸ìš© ê²€ì‚¬ (ë¹ ë¥¸ ê²½ë¡œ)
    const lexicalResult = await this.lexicalAligner.calculateAlignment(
      answer,
      evidence,
    );

    if (lexicalResult.method === "direct_quote") {
      // ì§ì ‘ ì¸ìš©ì´ë©´ LLM í˜¸ì¶œ ìƒëµ
      return lexicalResult;
    }

    // 2. LLM ê¸°ë°˜ ì˜ë¯¸ ì •ë ¬ (ì˜ì—­/ì¶”ë¡  ê²€ì‚¬)
    const prompt = `
ë‹¤ìŒ ë‘ ë¬¸ì¥ì˜ ì˜ë¯¸ ì •ë ¬ì„ í‰ê°€í•˜ì„¸ìš”:

Evidence: "${evidence}"
Answer: "${answer}"

í‰ê°€ ê¸°ì¤€:
1. ë‹µë³€ì´ Evidenceë¥¼ ì§ì ‘ ì¸ìš©í•˜ëŠ”ê°€? (direct_quote)
2. ë‹µë³€ì´ Evidenceë¥¼ ì˜ì—­í–ˆëŠ”ê°€? (paraphrase)
3. ë‹µë³€ì´ Evidenceì—ì„œ ì¶”ë¡  ê°€ëŠ¥í•œê°€? (inference)
4. ë‹µë³€ê³¼ Evidenceê°€ ê´€ë ¨ ì—†ëŠ”ê°€? (unrelated)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{
  "method": "direct_quote | paraphrase | inference | unrelated",
  "score": 0.0 ~ 1.0,
  "reasoning": "ì„¤ëª…"
}`;

    const response = await this.llm.complete(prompt);
    const result = JSON.parse(response);

    return {
      score: result.score,
      method: result.method,
      confidence: 0.9,
      matchedSpans: [],
    };
  }
}
```

### 3.3 Question Classification (domain/classification/)

#### A. Question Classifier ì¸í„°í˜ì´ìŠ¤

```typescript
// src/domain/classification/question-classifier.ts (ì‹ ê·œ)

export type QuestionType =
  | "analytical"
  | "procedural"
  | "comparative"
  | "factual";

export interface QuestionClassifier {
  classify(question: string): QuestionType;
  classifyWithConfidence(question: string): {
    type: QuestionType;
    confidence: number;
  };
}
```

#### B. Pattern Classifier (ê¸°ì¡´ ì •ê·œì‹ ê¸°ë°˜)

```typescript
// src/domain/classification/pattern-classifier.ts (ì‹ ê·œ, ê¸°ì¡´ ì½”ë“œ ì´ê´€)

export class PatternClassifier implements QuestionClassifier {
  private patterns = {
    analytical: /ì™œ|ì´ìœ |ì›ì¸|ê¹Œë‹­/,
    procedural: /ì–´ë–»ê²Œ|ë°©ë²•|ê³¼ì •|ì ˆì°¨/,
    comparative: /ì°¨ì´|ë¹„êµ|ë‹¤ë¥¸|ìœ ì‚¬|ê°™ì€/,
    factual: /ë¬´ì—‡|ëˆ„ê°€|ì–¸ì œ|ì–´ë””/,
  };

  classify(question: string): QuestionType {
    const q = question.toLowerCase();

    // ìš°ì„ ìˆœìœ„: analytical > procedural > comparative > factual
    if (this.patterns.analytical.test(q)) return "analytical";
    if (this.patterns.procedural.test(q)) return "procedural";
    if (this.patterns.comparative.test(q)) return "comparative";
    if (this.patterns.factual.test(q)) return "factual";

    return "factual"; // ê¸°ë³¸ê°’
  }

  classifyWithConfidence(question: string): {
    type: QuestionType;
    confidence: number;
  } {
    const type = this.classify(question);

    // ì‹ ë¢°ë„ ê³„ì‚° (íŒ¨í„´ ë§¤ì¹­ ê°•ë„)
    const q = question.toLowerCase();
    const pattern = this.patterns[type];
    const matches = q.match(pattern);

    const confidence = matches ? 0.8 : 0.5; // ë§¤ì¹­ë˜ë©´ 0.8, ê¸°ë³¸ê°’ì´ë©´ 0.5

    return { type, confidence };
  }
}
```

---

## 4. ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### 4.1 ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜

#### Phase 1: Domain ê³„ì¸µ êµ¬ì¶• (2-3ì‹œê°„)

**ì‘ì—… ë‚´ìš©**:

1. `src/domain/` í´ë” ìƒì„±
2. Entity Extraction ëª¨ë“ˆ êµ¬í˜„
   - `entity-recognizer.ts` (ì¸í„°í˜ì´ìŠ¤)
   - `korean-ner.ts` (NER)
   - `entity-dictionary.ts` (ë„ë©”ì¸ ì‚¬ì „)
   - `composite-extractor.ts` (ê²°í•©)
3. Evidence Alignment ëª¨ë“ˆ êµ¬í˜„
   - `semantic-aligner.ts` (ì¸í„°í˜ì´ìŠ¤)
   - `citation-detector.ts` (ì§ì ‘ ì¸ìš© ê²€ì¶œ)
   - `lexical-aligner.ts` (ê¸°ì¡´ ì½”ë“œ ì´ê´€)
4. Question Classification ëª¨ë“ˆ êµ¬í˜„
   - `question-classifier.ts` (ì¸í„°í˜ì´ìŠ¤)
   - `pattern-classifier.ts` (ê¸°ì¡´ ì½”ë“œ ì´ê´€)

**í…ŒìŠ¤íŠ¸**:

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
npm run test tests/domain/extraction/
npm run test tests/domain/alignment/
npm run test tests/domain/classification/

# íƒ€ì… ì²´í¬
npm run typecheck
```

#### Phase 2: Diversity Planner Agent ìƒì„± (1-2ì‹œê°„)

**ì‘ì—… ë‚´ìš©**:

1. `src/agents/diversityPlanner.ts` ìƒì„±
2. Domain ëª¨ë“ˆ í†µí•©
3. í’ˆì§ˆ ëª©í‘œ ì„¤ì • ë¡œì§ êµ¬í˜„
4. ìƒì„± ê³„íš ìˆ˜ë¦½ ë¡œì§ êµ¬í˜„

**í…ŒìŠ¤íŠ¸**:

```bash
npm run test tests/agents/diversityPlanner.test.ts
```

#### Phase 3: Metrics ë¦¬íŒ©í† ë§ (1-2ì‹œê°„)

**ì‘ì—… ë‚´ìš©**:

1. `coverageMetrics.ts` ê°œì„ 
   - CompositeExtractor ì‚¬ìš©
   - ê¸°ì¡´ extractKeyPhrases ì œê±°
2. `evidenceQuality.ts` ê°œì„ 
   - LexicalAligner ì‚¬ìš©
   - ê¸°ì¡´ calculateSnippetAlignment ì œê±°
3. `qtypeDistribution.ts` ê°œì„ 
   - PatternClassifier ì‚¬ìš©

**í…ŒìŠ¤íŠ¸**:

```bash
npm run test tests/quality/

# íšŒê·€ í…ŒìŠ¤íŠ¸
npm run baseline:generate -- --input test-data/sample.json --output test-results/baseline.json
```

#### Phase 4: í”¼ë“œë°± ë£¨í”„ êµ¬ì¶• (2-3ì‹œê°„)

**ì‘ì—… ë‚´ìš©**:

1. `QAGenerator` ê°œì„ 
   - `generateQAWithFeedback` ë©”ì„œë“œ ì¶”ê°€
   - `regenerateWithFeedback` ë©”ì„œë“œ ì¶”ê°€
2. Orchestrator í†µí•©
   - Diversity Planner í˜¸ì¶œ
   - í”¼ë“œë°± ë£¨í”„ ì—°ê²°
3. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
   - Regeneration íšŸìˆ˜ ì¶”ì 
   - í’ˆì§ˆ ê°œì„  ë©”íŠ¸ë¦­

**í…ŒìŠ¤íŠ¸**:

```bash
npm run test tests/integration/feedback-loop.test.ts
npm run dev -- --qa-count 100
```

#### Phase 5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬ (1ì‹œê°„)

**ì‘ì—… ë‚´ìš©**:

1. ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
2. 100ê°œ ìƒ˜í”Œ ìƒì„± ë° ë©”íŠ¸ë¦­ ë¹„êµ
3. ë¬¸ì„œ ì—…ë°ì´íŠ¸
4. ë°°í¬

**í…ŒìŠ¤íŠ¸**:

```bash
npm run typecheck
npm run lint
npm run test
npm run ci:quality

# Baseline ë¹„êµ
npm run baseline:compare -- --before baseline-before.json --after baseline-after.json
```

### 4.2 í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥

**ì›ì¹™**:

1. **ê¸°ì¡´ API ìœ ì§€**: ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤ ë³€ê²½ ì—†ìŒ
2. **Feature Flag**: `ENABLE_ENHANCED_METRICS=true/false`
3. **Fallback**: ì‹ ê·œ ëª¨ë“ˆ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©

**êµ¬í˜„ ì˜ˆì‹œ**:

```typescript
// src/scripts/metrics/coverageMetrics.ts (ê°œì„ )

import { CompositeExtractor } from "../../domain/extraction/composite-extractor.js";

const ENABLE_ENHANCED_METRICS = process.env.ENABLE_ENHANCED_METRICS === "true";

export function calculateCoverageMetrics(
  qaItems: QAItem[],
  sourceTexts: string[],
  config: CoverageConfig,
): CoverageMetrics {
  if (ENABLE_ENHANCED_METRICS) {
    // âœ… ì‹ ê·œ ë¡œì§ (domain ëª¨ë“ˆ ì‚¬ìš©)
    return calculateEnhancedCoverage(qaItems, sourceTexts, config);
  } else {
    // âœ… ê¸°ì¡´ ë¡œì§ (í•˜ìœ„ í˜¸í™˜)
    return calculateLegacyCoverage(qaItems, sourceTexts, config);
  }
}

function calculateEnhancedCoverage(
  qaItems: QAItem[],
  sourceTexts: string[],
  config: CoverageConfig,
): CoverageMetrics {
  const extractor = new CompositeExtractor();
  // ... domain ëª¨ë“ˆ ì‚¬ìš©
}

function calculateLegacyCoverage(
  qaItems: QAItem[],
  sourceTexts: string[],
  config: CoverageConfig,
): CoverageMetrics {
  // ê¸°ì¡´ extractKeyPhrases ì‚¬ìš©
  // ... ê¸°ì¡´ ë¡œì§
}
```

### 4.3 ë¡¤ë°± ê³„íš

**ì¡°ê±´**:

- íƒ€ì… ì²´í¬ ì‹¤íŒ¨ ì‹œ
- í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ìœ¨ > 10% ì‹œ
- ë©”íŠ¸ë¦­ ì €í•˜ > 10% ì‹œ

**ë¡¤ë°± ì ˆì°¨**:

```bash
# 1. Feature Flag OFF
export ENABLE_ENHANCED_METRICS=false

# 2. Git revert (ìµœí›„ ìˆ˜ë‹¨)
git revert HEAD~5..HEAD

# 3. ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸
npm run build
npm run test
```

---

## 5. ì˜ˆìƒ íš¨ê³¼

### 5.1 ë©”íŠ¸ë¦­ ê°œì„ 

| ì§€í‘œ                   | í˜„ì¬         | ëª©í‘œ       | ê°œì„  ë°©ë²•                    |
| ---------------------- | ------------ | ---------- | ---------------------------- |
| **ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€**    | 46.7%        | 85%+       | NER + ë„ë©”ì¸ ì‚¬ì „            |
| **Evidence Alignment** | ~46%         | 85%+       | ì§ì ‘ ì¸ìš© ê°•í™” + í”¼ë“œë°± ë£¨í”„ |
| **ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜**     | âœ… ìˆ˜ì • ì™„ë£Œ | 4ê°€ì§€ ê· í˜• | Agent ì—°ë™                   |

### 5.2 í’ˆì§ˆ í–¥ìƒ

**Before (Phase 1)**:

```json
{
  "entity_coverage_rate": 0.467,
  "alignment_score": 0.269,
  "classified_type": "factual"
}
```

**After (Phase 2)**:

```json
{
  "entity_coverage_rate": 0.87, // â¬† 86% ì¦ê°€
  "alignment_score": 0.89, // â¬† 231% ì¦ê°€
  "classified_type": "analytical",
  "confidence": 0.8,
  "regeneration_count": 1 // í”¼ë“œë°± ë£¨í”„ ì‘ë™
}
```

### 5.3 ì•„í‚¤í…ì²˜ ê°œì„ 

**Before**:

- ë¶„ì‚°ëœ ì±…ì„ (agents/metrics/tools)
- í”¼ë“œë°± ë£¨í”„ ë¶€ì¬
- ê·œì¹™ ê¸°ë°˜ (NER ì—†ìŒ, ë¬¸ì ìœ ì‚¬ë„)

**After**:

- ëª…í™•í•œ ê³„ì¸µ (domain/agents/metrics)
- í”¼ë“œë°± ë£¨í”„ êµ¬ì¶•
- LLM í™œìš© ê°•í™” (NER + ì˜ë¯¸ ì •ë ¬)

---

## 6. ë¦¬ìŠ¤í¬ ë° ì™„í™”

### 6.1 ë¦¬ìŠ¤í¬

| ë¦¬ìŠ¤í¬               | í™•ë¥  | ì˜í–¥ë„ | ì™„í™” ì „ëµ                          |
| -------------------- | ---- | ------ | ---------------------------------- |
| **íƒ€ì… ì•ˆì •ì„± ì €í•˜** | ì¤‘   | ë†’ìŒ   | ë‹¨ê³„ë³„ íƒ€ì… ì²´í¬ + pre-commit hook |
| **ì„±ëŠ¥ ì €í•˜**        | ì¤‘   | ì¤‘     | ë²¤ì¹˜ë§ˆí¬ + Feature Flag + Fallback |
| **ë©”íŠ¸ë¦­ ì €í•˜**      | ë‚®   | ë†’ìŒ   | Baseline ë¹„êµ + ë¡¤ë°± ê³„íš          |
| **êµ¬í˜„ ì§€ì—°**        | ì¤‘   | ì¤‘     | ë‹¨ê³„ë³„ ë§ˆì¼ìŠ¤í†¤ + ìš°ì„ ìˆœìœ„ ì¡°ì •    |

### 6.2 ì™„í™” ì „ëµ

#### A. íƒ€ì… ì•ˆì •ì„±

```bash
# ê° ë‹¨ê³„ë§ˆë‹¤ íƒ€ì… ì²´í¬
npm run typecheck

# pre-commit hook í™œìš©
npm run ci:quality
```

#### B. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```typescript
// ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
import { performance } from "perf_hooks";

const start = performance.now();
const result = await extractor.extractEntities(texts);
const duration = performance.now() - start;

if (duration > 1000) {
  console.warn(`Performance degradation: ${duration}ms`);
}
```

#### C. ë©”íŠ¸ë¦­ ë¹„êµ

```bash
# Before baseline ìƒì„±
npm run baseline:generate -- --output baseline-before.json

# ê°œì„  í›„ baseline ìƒì„±
npm run baseline:generate -- --output baseline-after.json

# ë¹„êµ
npm run baseline:compare -- --before baseline-before.json --after baseline-after.json
```

---

## 7. ë‹¤ìŒ ë‹¨ê³„ (Action Items)

### ì¦‰ì‹œ (ì˜¤ëŠ˜)

- [ ] **RFC ê²€í†  ë° ìŠ¹ì¸** (Architecture Team)
- [ ] **Phase 1 ì‹œì‘**: Domain ê³„ì¸µ êµ¬ì¶•
  - [ ] `src/domain/` í´ë” ìƒì„±
  - [ ] Entity Extraction ëª¨ë“ˆ êµ¬í˜„
  - [ ] Evidence Alignment ëª¨ë“ˆ êµ¬í˜„
  - [ ] Question Classification ëª¨ë“ˆ êµ¬í˜„
  - [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

### ë‹¨ê¸° (ë‚´ì¼)

- [ ] **Phase 2**: Diversity Planner Agent ìƒì„±
- [ ] **Phase 3**: Metrics ë¦¬íŒ©í† ë§
- [ ] **Phase 4**: í”¼ë“œë°± ë£¨í”„ êµ¬ì¶•
- [ ] **Phase 5**: í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬

### ì¤‘ê¸° (í–¥í›„)

- [ ] **LLM Aligner êµ¬í˜„** (Phase 3)
- [ ] **ì„ë² ë”© í™œìš©** (Vector similarity)
- [ ] **ë„ë©”ì¸ ì‚¬ì „ í™•ì¥** (ë‹¤ë¥¸ ë„ë©”ì¸ ì¶”ê°€)
- [ ] **ìë™ í”¼ë“œë°± ë£¨í”„ ìµœì í™”** (ì¬ì‹œë„ íšŸìˆ˜ ë™ì  ì¡°ì •)

---

## 8. ì°¸ê³  ë¬¸ì„œ

- `docs/fixes/P2_DESIGN_ANALYSIS_2025-10-07.md` (ì„¤ê³„ ë¶„ì„)
- `docs/fixes/P2_PHASE1_COMPLETE_2025-10-07.md` (Phase 1 ì™„ë£Œ ë³´ê³ ì„œ)
- `docs/P2_QUALITY_IMPROVEMENT_PLAN.md` (ê¸°ì¡´ ê³„íš)
- `src/scripts/metrics/coverageMetrics.ts` (í˜„ì¬ êµ¬í˜„)
- `src/scripts/metrics/evidenceQuality.ts` (í˜„ì¬ êµ¬í˜„)
- `src/scripts/metrics/qtypeDistribution.ts` (í˜„ì¬ êµ¬í˜„)

---

**ìŠ¹ì¸ ì„œëª…**:

- [ ] Architecture Team
- [ ] QA Team
- [ ] DevOps Team

**ì˜ˆìƒ ì™„ë£Œì¼**: 2025-10-08 (2ì¼)
**ë¦¬ìŠ¤í¬ ìˆ˜ì¤€**: ğŸŸ¡ Medium (Feature Flag + Fallbackìœ¼ë¡œ ì™„í™”)
