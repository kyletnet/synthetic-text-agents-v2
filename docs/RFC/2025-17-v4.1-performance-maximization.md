# RFC: v4.1 Performance Maximization - "최극상 성능 전략"

**Status**: Execution Plan
**Created**: 2025-10-09 01:00 KST
**Owner**: System Architecture Team
**Approach**: Incremental Performance Upgrades (Phase 2.6-3.0)
**Philosophy**: "운영 효율 때문에 넣지 못했던 고급 탐색·제약·재순위·보상·검증을 이제 전부 켠다"

---

## Executive Summary

이 RFC는 **RFC 2025-16 (v4 Cathedral & Forge)**를 기반으로, ChatGPT가 제안한 **"최극상 성능" Top-15 업그레이드**를 각 Phase에 통합합니다.

**핵심 전략**:
1. ✅ 기존 v4 로드맵 유지 (Phase 2.6-3.0, 18주)
2. ✅ 각 Phase에 성능 업그레이드 추가 (Quick Wins / Core Upgrades / Strategic)
3. ✅ Mock 금지 유지, WebView는 마지막
4. ✅ 모든 업그레이드는 Adapter/Registry로 플러그인화 (무중단 교체)

**예상 성능 향상**:
- Groundedness: **73% → 85%** (+12%p) - NLI Gate + Evidence-Locked + Re-rank
- Recall@10: **+20%** - SPLADE/ColBERT + Hybrid + MMR/RRF
- Readability: **+10%** - AOL/GCG + Cognitive Load Control
- Cost/1kQA: **-25%** - Bandit/Pareto + Cache + Batch
- Compliance: **≥95%** - HIPAA/SOX/ISO Packs

---

## 0. Top-15 Performance Upgrades (Overview)

### Quick Wins (≤2주, Phase 2.6)
1. **Cross-Encoder Re-ranker** (bge-reranker-large) → Groundedness +8-12%p
2. **SPLADE/ColBERT Hybrid** (Late-Interaction) → Recall@10 +10-15%
3. **Evidence-Locked Decoding** (Constraint framework) → Hallucination 대폭 감소
4. **NLI Entailment Gate** (DeBERTa-v3) → 근거 불일치 자동 차단
5. **MMR/RRF Fusion** (Reciprocal Rank Fusion) → 중복 감소, 다양성 ↑
6. **Feedback Mapping JSON** (Intent→Param) → 피드백 반영률 ↑(≥70%)

### Core Upgrades (4-6주, Phase 2.7-2.8)
7. **AOL Registry + GCG Compiler** (≥30 operators, grammar v1) → 재현성·감사성 극대화
8. **Bandit + Pareto Router** (UCB/TS, 3D optimization) → 품질·비용·다양성 동시 최적화
9. **Multi-View Embedding** (BGE-M3, E5-Mistral) → 의미검색 견고성 ↑
10. **GPU Batched Re-ranking** + FAISS/HNSW tuning → Throughput ↑, Latency ↓
11. **Reward Model v1** (DPO/ORPO/KTO) → 자연성·독창성 균형
12. **Corpus Merkle-DAG** + Trust Anchors → 문서 무결성·회귀 추적 강화

### Strategic (8-12주, Phase 2.9-3.0)
13. **Contrast Sets & Counterfactual Operator** → 편향·누락 탐지, 독창성 ↑
14. **Federated Reward/Policy** (ε-DP) → 테넌트 간 지능 공유·프라이버시 보장
15. **Mutual Audit Gateway** (서명 로그 외부 검증) → 규제·고객 신뢰 압도적 차별화

---

## 1. Phase 2.6 (3 weeks): 4-Layer Runtime + Quick Wins

### Baseline Deliverables (RFC 2025-16)
```
src/runtime/
├── l1-retrieval/           # Hybrid orchestrator
├── l2-synthesizer/         # Intent/slot extraction
├── l3-planner/             # AOL + GCG (stubs)
└── l4-optimizer/           # Feedback interpreter
```

### ⭐ Performance Upgrades (NEW)

#### 1.1 Cross-Encoder Re-ranker (Quick Win #1)

**Implementation**:
```typescript
// src/runtime/l1-retrieval/cross-encoder-reranker.ts

import { pipeline } from "@xenova/transformers";

interface RerankResult {
  chunkId: string;
  score: number;
  originalRank: number;
  newRank: number;
}

class CrossEncoderReranker {
  private model: any;

  async initialize(): Promise<void> {
    // Use bge-reranker-large or ms-marco-MiniLM-L6-v2
    this.model = await pipeline(
      "text-classification",
      "BAAI/bge-reranker-large"
    );
  }

  async rerank(
    query: string,
    chunks: Chunk[],
    topK: number = 10
  ): Promise<RerankResult[]> {
    const pairs = chunks.map(c => [query, c.text]);
    const scores = await this.model(pairs);

    const results = chunks
      .map((c, i) => ({
        chunkId: c.id,
        score: scores[i].score,
        originalRank: i,
        newRank: -1
      }))
      .sort((a, b) => b.score - a.score)
      .slice(0, topK)
      .map((r, i) => ({ ...r, newRank: i }));

    return results;
  }
}
```

**Integration**:
```typescript
// src/runtime/l1-retrieval/hybrid-orchestrator.ts

class HybridOrchestrator {
  async retrieve(query: string): Promise<Chunk[]> {
    // 1. BM25 + Vector hybrid (α=0.6, β=0.4)
    const candidates = await this.hybridSearch(query, topK=50);

    // 2. Cross-Encoder re-rank
    const reranker = new CrossEncoderReranker();
    const reranked = await reranker.rerank(query, candidates, topK=10);

    // 3. MMR + RRF fusion (see below)
    const fused = await this.fusionStep(reranked);

    return fused;
  }
}
```

**Expected Gain**: Groundedness +8-12%p

---

#### 1.2 SPLADE/ColBERT Hybrid (Quick Win #2)

**Implementation** (Option A: SPLADE):
```typescript
// src/runtime/l1-retrieval/splade-adapter.ts

class SPLADEAdapter {
  private model: any;

  async initialize(): Promise<void> {
    this.model = await pipeline(
      "feature-extraction",
      "naver/splade-cocondenser-ensembledistil"
    );
  }

  async expand(query: string): Promise<string[]> {
    // SPLADE: Sparse lexical expansion
    const features = await this.model(query);
    const expandedTerms = this.extractTopTerms(features, topK=10);
    return expandedTerms;
  }

  private extractTopTerms(features: any, topK: number): string[] {
    // Extract top-K weighted terms
    return features
      .sort((a, b) => b.weight - a.weight)
      .slice(0, topK)
      .map(f => f.term);
  }
}
```

**Integration**:
```typescript
// src/runtime/l1-retrieval/hybrid-orchestrator.ts

class HybridOrchestrator {
  async hybridSearch(query: string, topK: number): Promise<Chunk[]> {
    // SPLADE expansion
    const splade = new SPLADEAdapter();
    const expandedTerms = await splade.expand(query);
    const expandedQuery = [query, ...expandedTerms].join(" ");

    // BM25 with expanded query
    const bm25Results = await this.bm25.search(expandedQuery, topK);

    // Vector search (original query)
    const vectorResults = await this.vector.search(query, topK);

    // Reciprocal Rank Fusion (RRF)
    const fused = this.rrf([bm25Results, vectorResults]);

    return fused;
  }
}
```

**Expected Gain**: Recall@10 +10-15%

---

#### 1.3 Evidence-Locked Decoding (Quick Win #3)

**Implementation**:
```typescript
// src/runtime/l3-planner/evidence-locked-decoder.ts

import { Guidance } from "guidance-ai"; // or Outlines, LMQL

interface DecodingConstraints {
  citationMandatory: boolean;
  spanCopyOnly: boolean;
  evidenceIds: string[];
  maxNewTokens: number;
}

class EvidenceLockedDecoder {
  /**
   * Constrained generation: Cite-first + Span-copy
   */
  async generate(
    prompt: string,
    evidence: Evidence[],
    constraints: DecodingConstraints
  ): Promise<string> {
    // Build guidance template
    const template = `
{{#system}}
You must cite evidence before generating.
Available evidence IDs: ${constraints.evidenceIds.join(", ")}
{{/system}}

{{#user}}
${prompt}
{{/user}}

{{#assistant}}
{{#if citationMandatory}}
[Evidence: {{select 'evidence_id' options=evidenceIds}}]
{{/if}}

{{gen 'response' max_tokens=${constraints.maxNewTokens}}}
{{/assistant}}
    `;

    const guidance = new Guidance(template);
    const result = await guidance.run({
      evidenceIds: constraints.evidenceIds,
      citationMandatory: constraints.citationMandatory
    });

    return result.response;
  }

  /**
   * Post-generation: NLI entailment check
   */
  async verifyEntailment(
    generated: string,
    evidence: Evidence[]
  ): Promise<boolean> {
    const nliGate = new NLIGate();
    const entailed = await nliGate.check(generated, evidence);
    return entailed;
  }
}
```

**Expected Gain**: Hallucination 대폭 감소 (정량 측정 필요)

---

#### 1.4 NLI Entailment Gate (Quick Win #4)

**Implementation**:
```typescript
// src/runtime/l3-planner/nli-gate.ts

import { pipeline } from "@xenova/transformers";

class NLIGate {
  private model: any;

  async initialize(): Promise<void> {
    // DeBERTa-v3-large MNLI
    this.model = await pipeline(
      "text-classification",
      "microsoft/deberta-v3-large-mnli"
    );
  }

  /**
   * Check if generated text is entailed by evidence
   *
   * @returns true if entailment, false if contradiction/neutral
   */
  async check(generated: string, evidence: Evidence[]): Promise<boolean> {
    const sentences = this.splitSentences(generated);

    for (const sentence of sentences) {
      let entailed = false;

      // Check against all evidence
      for (const ev of evidence) {
        const result = await this.model({
          premise: ev.text,
          hypothesis: sentence
        });

        if (result.label === "entailment" && result.score > 0.8) {
          entailed = true;
          break;
        }
      }

      // If any sentence is not entailed, reject
      if (!entailed) {
        console.warn(`[NLI Gate] Sentence not entailed: "${sentence}"`);
        return false;
      }
    }

    return true;
  }

  private splitSentences(text: string): string[] {
    return text.split(/[.!?]+/).filter(s => s.trim().length > 0);
  }
}
```

**Expected Gain**: 근거 불일치 문장 자동 제거 (근거성 ↑)

---

#### 1.5 MMR/RRF Fusion (Quick Win #5)

**Implementation**:
```typescript
// src/runtime/l1-retrieval/fusion.ts

class RetrievalFusion {
  /**
   * Reciprocal Rank Fusion (RRF)
   *
   * Score(d) = Σ 1/(k + rank_i(d))  where k=60 (standard)
   */
  rrf(resultSets: Chunk[][], k: number = 60): Chunk[] {
    const scores = new Map<string, number>();

    for (const results of resultSets) {
      results.forEach((chunk, rank) => {
        const currentScore = scores.get(chunk.id) || 0;
        scores.set(chunk.id, currentScore + 1 / (k + rank));
      });
    }

    // Sort by RRF score
    return Array.from(scores.entries())
      .sort((a, b) => b[1] - a[1])
      .map(([id, score]) => {
        const chunk = this.findChunkById(id, resultSets);
        return { ...chunk, rrfScore: score };
      });
  }

  /**
   * Maximal Marginal Relevance (MMR)
   *
   * MMR = argmax [λ*Sim(q,d) - (1-λ)*max Sim(d,d_i)]
   */
  mmr(
    query: string,
    candidates: Chunk[],
    selected: Chunk[],
    lambda: number = 0.7
  ): Chunk {
    const scores = candidates.map(c => {
      const relevance = this.similarity(query, c.text);
      const maxSimilarity = selected.length > 0
        ? Math.max(...selected.map(s => this.similarity(c.text, s.text)))
        : 0;

      return {
        chunk: c,
        mmrScore: lambda * relevance - (1 - lambda) * maxSimilarity
      };
    });

    return scores.sort((a, b) => b.mmrScore - a.mmrScore)[0].chunk;
  }

  private similarity(text1: string, text2: string): number {
    // Cosine similarity (simplified - use embedding in production)
    return 0.5; // Placeholder
  }
}
```

**Expected Gain**: 중복 -20%, 다양성 ↑

---

#### 1.6 Feedback Mapping JSON (Quick Win #6)

**Implementation**:
```json
// configs/feedback-mapping.json

{
  "intent_to_params": {
    "incorrect": {
      "retrieval": {
        "alpha": 0.8,
        "beta": 0.2,
        "min_trust_score": 0.7
      },
      "operators": ["verify-facts", "cross-reference"],
      "gcg": {
        "citation_mandatory": true,
        "min_sources": 2
      },
      "reward": {
        "groundedness_weight": 1.5
      }
    },

    "insufficient": {
      "retrieval": {
        "alpha": 0.6,
        "beta": 0.4,
        "top_k": 15
      },
      "operators": ["expand-context", "multi-view-synthesis"],
      "reward": {
        "coverage_weight": 1.3
      }
    },

    "evidence": {
      "retrieval": {
        "alpha": 0.7,
        "beta": 0.3,
        "min_sources": 2
      },
      "operators": ["multi-source-citation", "evidence-lock"],
      "gcg": {
        "citation_mandatory": true,
        "min_citations_per_paragraph": 1
      }
    },

    "brevity": {
      "operators": ["summarize", "cognitive-load-limit"],
      "gcg": {
        "max_sentence_length": 20,
        "structure": "bullet"
      },
      "reward": {
        "readability_weight": 1.3
      }
    },

    "contrast": {
      "operators": ["contrast-set-generator", "counterfactual-examples"],
      "reward": {
        "diversity_weight": 1.4,
        "originality_weight": 1.2
      }
    }
  },

  "modifiers": {
    "lexicon_strict": {
      "operators": ["domain-lexicon-fixer"],
      "gcg": {
        "domain_terms_required": true
      }
    },

    "structure_bullet": {
      "gcg": {
        "structure": "bullet",
        "bullet_max": 5
      }
    },

    "coverage_comprehensive": {
      "retrieval": {
        "top_k": 20
      },
      "operators": ["multi-aspect-coverage"]
    }
  }
}
```

**Usage**:
```typescript
// src/runtime/l4-optimizer/feedback-interpreter.ts

class FeedbackInterpreter {
  private mapping: FeedbackMapping;

  constructor() {
    this.mapping = JSON.parse(
      fs.readFileSync("configs/feedback-mapping.json", "utf-8")
    );
  }

  /**
   * Map feedback to system parameters
   */
  interpret(feedback: UserFeedback): SystemParameters {
    const intentParams = this.mapping.intent_to_params[feedback.intent];
    const modifierParams = feedback.modifiers.map(m => this.mapping.modifiers[m]);

    // Merge parameters
    return this.mergeParameters([intentParams, ...modifierParams]);
  }
}
```

**Expected Gain**: Feedback Utilization ≥70%

---

### Phase 2.6 Success Criteria (Updated)

**KPIs**:
- [ ] Recall@10: +10% (baseline → improved) ← **NEW: +10% from SPLADE/RRF**
- [ ] Groundedness: +8% (baseline → improved) ← **NEW: +8% from Cross-Encoder**
- [ ] Feedback Utilization: ≥70% ← **NEW: Feedback Mapping JSON**
- [ ] Intent classification accuracy: ≥85%
- [ ] NLI Gate: Entailment rate ≥90% ← **NEW**

**Tests**: 800+ passing (from 842)

**DoD**:
- [ ] Cross-Encoder re-ranker operational (bge-reranker-large)
- [ ] SPLADE/ColBERT adapter integrated (expansion working)
- [ ] Evidence-Locked decoder functional (constraints enforced)
- [ ] NLI Gate implemented (DeBERTa-v3, entailment check)
- [ ] MMR/RRF fusion working (diversity ↑)
- [ ] Feedback Mapping JSON deployed (intent→params)

---

## 2. Phase 2.7 (4 weeks): Genius Lab v1 + Core Upgrades

### Baseline Deliverables (RFC 2025-16)
```
src/offline/genius-lab/
├── persona-canon/          # 8 페르소나 규칙
├── aol/                    # ≥30 operators
├── gcg/                    # Grammar compiler
└── rewards/                # Composite scorer
```

### ⭐ Performance Upgrades (NEW)

#### 2.1 AOL Registry Formalization (Core #7)

**Registry Schema**:
```typescript
// src/offline/genius-lab/aol/registry.json

{
  "operators": [
    {
      "id": "paraphrase-with-citation",
      "version": "1.0.0",
      "category": "semantic",
      "status": "champion",
      "input_schema": {
        "text": "string",
        "evidence": "Evidence[]"
      },
      "output_schema": {
        "paraphrased": "string",
        "citations": "string[]"
      },
      "evidence_level": "required",
      "cost_tier": 2,
      "risk_level": "low",
      "performance": {
        "avg_latency_ms": 150,
        "success_rate": 0.98
      }
    },

    {
      "id": "contrast-set-generator",
      "version": "1.0.0",
      "category": "cognitive",
      "status": "champion",
      "input_schema": {
        "text": "string"
      },
      "output_schema": {
        "contrasts": "string[]"
      },
      "evidence_level": "optional",
      "cost_tier": 3,
      "risk_level": "medium",
      "performance": {
        "avg_latency_ms": 300,
        "success_rate": 0.92
      }
    },

    // ... 28 more operators
  ]
}
```

**Registry Manager**:
```typescript
// src/runtime/l3-planner/operator-registry.ts

class OperatorRegistry {
  private operators: Map<string, Operator> = new Map();
  private metadata: Map<string, OperatorMeta> = new Map();

  loadFromFile(path: string): void {
    const registry = JSON.parse(fs.readFileSync(path, "utf-8"));
    registry.operators.forEach(op => {
      this.register(this.instantiateOperator(op.id), op);
    });
  }

  dispatch(intent: string, modifiers: Modifier[]): Operator[] {
    // Load from feedback-mapping.json
    const mapping = this.loadFeedbackMapping();
    const operatorIds = mapping.intent_to_params[intent].operators;

    return operatorIds.map(id => this.get(id));
  }

  promote(id: string): void {
    const meta = this.metadata.get(id);
    if (meta.status === "canary") {
      meta.status = "champion";
      this.metadata.set(id, meta);
      this.saveRegistry();
    }
  }
}
```

**Expected Gain**: 탐색·실험 속도 ↑, 품질 일관성 ↑

---

#### 2.2 GCG Compiler (Core #7)

Already documented in `docs/GUIDELINES_TO_GCG.md`. See implementation there.

**Expected Gain**: 규정 위반 → 0에 가깝게

---

#### 2.3 Multi-View Embedding (Core #9)

**Implementation**:
```typescript
// src/runtime/l1-retrieval/multi-view-embedder.ts

class MultiViewEmbedder {
  private models: any[];

  async initialize(): Promise<void> {
    this.models = [
      await pipeline("feature-extraction", "BAAI/bge-m3"),
      await pipeline("feature-extraction", "intfloat/e5-mistral-7b-instruct")
    ];
  }

  /**
   * Generate multiple embedding views
   */
  async embed(text: string): Promise<number[][]> {
    const embeddings = await Promise.all(
      this.models.map(m => m(text))
    );
    return embeddings; // [[768], [4096]]
  }

  /**
   * Ensemble retrieval: Average rankings
   */
  async retrieve(query: string, topK: number): Promise<Chunk[]> {
    const views = await this.embed(query);
    const resultSets = await Promise.all(
      views.map((v, i) => this.vectorDB.search(v, topK, index=i))
    );

    // RRF fusion
    const fusion = new RetrievalFusion();
    return fusion.rrf(resultSets);
  }
}
```

**Expected Gain**: 의미검색 견고성 ↑ (Recall@K +5-8%)

---

#### 2.4 GPU Batched Re-ranking (Core #10)

**Implementation**:
```typescript
// src/runtime/l1-retrieval/batch-reranker.ts

class BatchReranker {
  private model: any;
  private batchSize: number = 32;

  /**
   * Batch re-ranking for throughput
   */
  async rerankBatch(
    queries: string[],
    candidateSets: Chunk[][],
    topK: number
  ): Promise<Chunk[][]> {
    // Flatten all pairs
    const pairs: [string, string][] = [];
    const indices: number[] = [];

    queries.forEach((q, i) => {
      candidateSets[i].forEach(c => {
        pairs.push([q, c.text]);
        indices.push(i);
      });
    });

    // Batch inference
    const scores = await this.model(pairs, { batch_size: this.batchSize });

    // Group by query
    const grouped = new Map<number, Array<{ chunk: Chunk; score: number }>>();
    scores.forEach((s, i) => {
      const queryIdx = indices[i];
      if (!grouped.has(queryIdx)) {
        grouped.set(queryIdx, []);
      }
      grouped.get(queryIdx).push({
        chunk: candidateSets[queryIdx][i % candidateSets[queryIdx].length],
        score: s.score
      });
    });

    // Sort and slice top-K
    return Array.from(grouped.values()).map(results =>
      results.sort((a, b) => b.score - a.score).slice(0, topK).map(r => r.chunk)
    );
  }
}
```

**FAISS Tuning**:
```python
# scripts/faiss-tuning.py

import faiss
import numpy as np

def tune_hnsw(vectors, ef_search=128, M=32):
    """
    Tune HNSW index for optimal recall/latency

    ef_search: Higher = better recall, slower
    M: Higher = better recall, more memory
    """
    index = faiss.IndexHNSWFlat(vectors.shape[1], M)
    index.hnsw.efSearch = ef_search
    index.add(vectors)
    return index

def tune_ivf_pq(vectors, nlist=100, m=8, nbits=8):
    """
    Tune IVF-PQ for compression

    nlist: Number of clusters
    m: Number of subvectors
    nbits: Bits per subvector
    """
    quantizer = faiss.IndexFlatL2(vectors.shape[1])
    index = faiss.IndexIVFPQ(quantizer, vectors.shape[1], nlist, m, nbits)
    index.train(vectors)
    index.add(vectors)
    return index
```

**Expected Gain**: Throughput +50%, Latency -30%

---

#### 2.5 Reward Model v1 (Core #11)

**Implementation** (DPO-based):
```typescript
// src/offline/genius-lab/rewards/dpo-trainer.ts

class DPORewardTrainer {
  /**
   * Train reward model using Direct Preference Optimization
   *
   * Input: Pairs of (preferred, rejected) responses
   * Output: Reward model that scores responses
   */
  async train(pairs: PreferencePair[]): Promise<RewardModel> {
    // Implement DPO loss:
    // L = -log σ(β * (log π_θ(y_w|x) - log π_ref(y_w|x)
    //              - (log π_θ(y_l|x) - log π_ref(y_l|x))))

    // For v1, use simple pairwise ranking loss
    const model = await this.trainPairwise(pairs);
    return model;
  }

  private async trainPairwise(pairs: PreferencePair[]): Promise<RewardModel> {
    // Train a classifier to predict which response is better
    // Use features: groundedness, naturalness, originality, compliance, tone

    const features = pairs.map(p => ({
      preferred: this.extractFeatures(p.preferred),
      rejected: this.extractFeatures(p.rejected)
    }));

    // Train logistic regression or small neural network
    const model = await this.fitClassifier(features);
    return model;
  }

  private extractFeatures(response: string): Features {
    return {
      groundedness: this.scoreGroundedness(response),
      naturalness: this.scoreNaturalness(response),
      originality: this.scoreOriginality(response),
      compliance: this.scoreCompliance(response),
      tone: this.scoreTone(response)
    };
  }
}
```

**Composite Scorer**:
```typescript
// src/offline/genius-lab/rewards/composite.ts

const DEFAULT_WEIGHTS = {
  naturalness: 0.25,
  groundedness: 0.30,
  originality: 0.15,
  compliance: 0.20,
  tone_consistency: 0.10
};

function computeCompositeReward(scores: Scores, weights = DEFAULT_WEIGHTS): number {
  return Object.entries(weights)
    .reduce((sum, [key, weight]) => sum + scores[key] * weight, 0);
}
```

**Expected Gain**: 자연성·독창성 균형 (주관적, A/B 테스트 필요)

---

### Phase 2.7 Success Criteria (Updated)

**KPIs**:
- [ ] Groundedness: +12%p (73% → 85%) ← **Includes NLI + Re-rank gains**
- [ ] Readability: +10%
- [ ] GCG compliance: ≥98%
- [ ] AOL operators: ≥30 deployed
- [ ] Reward model: Pairwise accuracy ≥75% ← **NEW**

**Tests**: 850+ passing

**DoD**:
- [ ] AOL Registry operational (30+ operators, metadata complete)
- [ ] GCG Compiler functional (guideline → grammar)
- [ ] Multi-View Embedding deployed (BGE-M3 + E5-Mistral)
- [ ] GPU Batch Re-ranking operational (throughput ↑)
- [ ] Reward Model v1 trained (DPO/Pairwise, composite scorer)

---

## 3. Phase 2.8 (3 weeks): Bandit + Pareto + Optimization

### Baseline Deliverables (RFC 2025-16)
```
src/runtime/l4-optimizer/
├── bandit-policy.ts
├── pareto-router.ts
└── graceful-degradation.ts

src/control/
├── experiment-catalog.ts
└── cost-tracker.ts
```

### ⭐ Performance Upgrades (NEW)

#### 3.1 Bandit Orchestration (Core #8)

Already specified in RFC 2025-16. Key enhancements:
- **Slate Bandit**: Select combinations of (model, prompt, operators) as single action
- **Contextual Bandit**: Use tenant_id/domain/doc_type/budget as context
- **Thompson Sampling**: Bayesian approach for better exploration

**Slate Bandit Example**:
```typescript
// src/runtime/l4-optimizer/slate-bandit.ts

interface Action {
  model: string;
  prompt: string;
  operators: string[];
}

class SlateBandit {
  /**
   * Select optimal (model, prompt, operators) combination
   */
  selectAction(context: Context): Action {
    // Thompson Sampling for slate
    const samples = this.sampleRewards(context);
    const bestAction = samples.sort((a, b) => b.reward - a.reward)[0];
    return bestAction.action;
  }

  updateReward(action: Action, reward: number, context: Context): void {
    // Bayesian update
    this.updatePosterior(action, reward, context);
  }
}
```

**Expected Gain**: 품질 유지하며 비용·지연 최적화

---

#### 3.2 Pareto Router (Core #8)

Already specified in RFC 2025-16. Key: 3D Pareto frontier (Quality, Cost, Diversity).

**Expected Gain**: Cost/1kQA -25%

---

#### 3.3 Corpus Merkle-DAG (Core #12)

**Implementation**:
```typescript
// src/control/corpus/merkle-dag.ts

import * as crypto from "crypto";

interface DocumentNode {
  id: string;
  content: string;
  hash: string;
  parentHashes: string[];
  timestamp: Date;
  trustAnchors: string[]; // Trusted source signatures
}

class CorpusMerkleDAG {
  private nodes: Map<string, DocumentNode> = new Map();

  /**
   * Add document with provenance
   */
  addDocument(doc: Document, parents: string[]): string {
    const hash = this.computeHash(doc.content);
    const node: DocumentNode = {
      id: doc.id,
      content: doc.content,
      hash,
      parentHashes: parents,
      timestamp: new Date(),
      trustAnchors: doc.signatures || []
    };

    this.nodes.set(doc.id, node);
    return hash;
  }

  /**
   * Verify document integrity
   */
  verify(docId: string): { valid: boolean; chain: string[] } {
    const node = this.nodes.get(docId);
    if (!node) return { valid: false, chain: [] };

    // Verify hash
    const computedHash = this.computeHash(node.content);
    if (computedHash !== node.hash) {
      return { valid: false, chain: [] };
    }

    // Verify parent chain
    const chain = this.buildChain(node);
    return { valid: true, chain };
  }

  /**
   * Detect document tampering
   */
  detectTampering(): DocumentNode[] {
    const tampered: DocumentNode[] = [];

    for (const [id, node] of this.nodes) {
      const computedHash = this.computeHash(node.content);
      if (computedHash !== node.hash) {
        tampered.push(node);
      }
    }

    return tampered;
  }

  private computeHash(content: string): string {
    return crypto.createHash("sha256").update(content).digest("hex");
  }

  private buildChain(node: DocumentNode): string[] {
    const chain = [node.hash];
    for (const parentHash of node.parentHashes) {
      const parent = this.findByHash(parentHash);
      if (parent) {
        chain.push(...this.buildChain(parent));
      }
    }
    return chain;
  }

  private findByHash(hash: string): DocumentNode | undefined {
    return Array.from(this.nodes.values()).find(n => n.hash === hash);
  }
}
```

**Expected Gain**: 문서 무결성 보장, 회귀 추적 (감사 강화)

---

### Phase 2.8 Success Criteria (Updated)

**KPIs**:
- [ ] Cost/1kQA: -25%
- [ ] p95 latency: ≤3s (Layer budget 준수)
- [ ] Bandit regret: ≤0.1
- [ ] Pareto optimality: 100% (all outputs on frontier)
- [ ] Corpus integrity: 100% (Merkle-DAG verification) ← **NEW**

**Tests**: 870+ passing

**DoD**:
- [ ] Slate Bandit operational (model+prompt+operators selection)
- [ ] Pareto Router operational (3D optimization)
- [ ] Corpus Merkle-DAG deployed (integrity verification)
- [ ] Cache hit rate: ≥60%
- [ ] GPU batch re-ranking: Throughput ↑

---

## 4. Phase 2.9 (3 weeks): Regulatory + Multi-tenant + Strategic

### Baseline Deliverables (RFC 2025-16)
```
src/offline/genius-lab/gcg/rules/
├── hipaa.yml
├── sox.yml
└── iso27001.yml

src/control/policy/
├── watchdog.ts
└── compliance-checker.ts

tenants/<id>/
```

### ⭐ Performance Upgrades (NEW)

#### 4.1 Contrast Sets & Counterfactual Operator (Strategic #13)

**Implementation**:
```typescript
// src/offline/genius-lab/aol/operators/contrast-set-generator.ts

class ContrastSetGenerator implements Operator {
  /**
   * Generate contrastive examples to detect bias/gaps
   *
   * Example:
   * Original: "High blood pressure is dangerous."
   * Contrast: "Low blood pressure is also dangerous."
   */
  async apply(text: string, evidence: Evidence[]): Promise<string[]> {
    const contrasts = await this.llm.generate(`
Generate 3 contrastive statements for: "${text}"

Contrasts should:
1. Flip key attributes (high→low, increase→decrease)
2. Negate main claim
3. Introduce alternative perspective

Output format: JSON array of strings
    `);

    return JSON.parse(contrasts);
  }

  /**
   * Counterfactual examples
   */
  async generateCounterfactuals(text: string): Promise<string[]> {
    const counterfactuals = await this.llm.generate(`
Generate counterfactual examples for: "${text}"

What if:
1. Key condition was different?
2. Context was reversed?
3. Opposite outcome occurred?
    `);

    return JSON.parse(counterfactuals);
  }
}
```

**Usage** (in Bias Detection):
```typescript
// Detect if model ignores important contrasts
const contrasts = await contrastGen.apply(response, evidence);
const modelResponses = await Promise.all(
  contrasts.map(c => model.generate(c))
);

// If all responses are identical → potential bias
const diversity = this.measureDiversity(modelResponses);
if (diversity < 0.3) {
  console.warn("Low diversity detected - potential bias");
}
```

**Expected Gain**: 편향·누락 탐지, 독창성 ↑

---

#### 4.2 Federated Reward/Policy (Strategic #14)

**Implementation** (ε-Differential Privacy):
```typescript
// src/control/federated/dp-aggregator.ts

import { addNoise, clipGradient } from "opacus"; // or TF-Privacy

class FederatedRewardAggregator {
  /**
   * Aggregate reward updates with ε-DP
   *
   * @param epsilon Privacy budget (e.g., 1.0)
   * @param delta Privacy failure probability (e.g., 1e-5)
   */
  async aggregateRewards(
    tenantUpdates: Map<string, RewardUpdate>,
    epsilon: number = 1.0,
    delta: number = 1e-5
  ): Promise<RewardModel> {
    // 1. Clip gradients (L2 norm)
    const clipped = Array.from(tenantUpdates.values()).map(u =>
      clipGradient(u.gradient, maxNorm=1.0)
    );

    // 2. Add Gaussian noise
    const noiseScale = this.computeNoiseScale(epsilon, delta, clipped.length);
    const noisy = clipped.map(g => addNoise(g, noiseScale));

    // 3. Average gradients
    const averaged = this.averageGradients(noisy);

    // 4. Update global reward model
    return this.updateModel(averaged);
  }

  private computeNoiseScale(epsilon: number, delta: number, n: number): number {
    // Gaussian mechanism: σ = (Δf / ε) * sqrt(2 * ln(1.25 / δ))
    const sensitivity = 1.0; // L2 sensitivity after clipping
    return (sensitivity / epsilon) * Math.sqrt(2 * Math.log(1.25 / delta));
  }
}
```

**Expected Gain**: 테넌트 간 지능 공유, 프라이버시 보장 (ε<1.0)

---

### Phase 2.9 Success Criteria (Updated)

**KPIs**:
- [ ] Compliance: ≥95% (HIPAA/SOX/ISO)
- [ ] Tenant drift: ≤2%
- [ ] Policy conflict detection: 100%
- [ ] Contrast set diversity: ≥0.7 ← **NEW**
- [ ] DP privacy: ε < 1.0 ← **NEW**

**Tests**: 890+ passing

**DoD**:
- [ ] HIPAA/SOX/ISO27001 GCG rules deployed
- [ ] Policy Watchdog operational (문서 변경 감지)
- [ ] Contrast Set Operator functional (bias detection)
- [ ] Federated Reward aggregation operational (DP-based)
- [ ] Multi-tenant isolation: Cross-tenant leakage = 0

---

## 5. Phase 3.0 (2 weeks): Trust Console SSR + Mutual Audit

### Baseline Deliverables (RFC 2025-16)
```
apps/fe-web/app/trust/
├── page.tsx
└── components/ (5 components)

apps/fe-web/app/api/trust/
└── *.ts (5 routes)
```

### ⭐ Performance Upgrades (NEW)

#### 5.1 Mutual Audit Gateway (Strategic #15)

**Implementation**:
```typescript
// apps/fe-web/app/api/trust/mutual-audit/route.ts

import { NextRequest, NextResponse } from "next/server";
import { TrustTokenVerifier } from "@/core/trust/trust-token-verifier";

export async function GET(request: NextRequest) {
  const url = new URL(request.url);
  const snapshotId = url.searchParams.get("snapshot_id");

  // Load snapshot
  const snapshot = await snapshotLogger.loadSnapshot(snapshotId);

  // Generate audit package (for external verification)
  const auditPackage = {
    snapshot,
    trustToken: snapshot.trustToken,
    evidenceHashes: snapshot.evidence.map(e => e.hash),
    signatureChain: snapshot.signatures,

    // Verification instructions
    verification: {
      steps: [
        "1. Verify TrustToken signature using public key",
        "2. Recompute evidence hashes and compare",
        "3. Validate C2PA signature chain",
        "4. Check snapshot checksum"
      ],
      publicKey: process.env.TRUST_PUBLIC_KEY,
      checksumAlgorithm: "SHA-256"
    }
  };

  return NextResponse.json(auditPackage);
}

/**
 * External verification tool (for customers)
 */
export async function POST(request: NextRequest) {
  const { snapshotId, customerSignature } = await request.json();

  // Load snapshot
  const snapshot = await snapshotLogger.loadSnapshot(snapshotId);

  // Verify customer can audit this snapshot
  const verifier = new TrustTokenVerifier();
  const valid = await verifier.verify(snapshot.trustToken);

  if (!valid) {
    return NextResponse.json({ error: "Invalid TrustToken" }, { status: 400 });
  }

  // Return audit trail
  return NextResponse.json({
    verified: true,
    auditTrail: snapshot.auditLog,
    evidence: snapshot.evidence,
    policyHistory: snapshot.policyChanges
  });
}
```

**Customer Verification Tool** (CLI):
```bash
#!/bin/bash
# scripts/customer-verify-snapshot.sh

SNAPSHOT_ID=$1
API_URL="https://your-api.com/api/trust/mutual-audit"

# 1. Download audit package
curl "$API_URL?snapshot_id=$SNAPSHOT_ID" > audit-package.json

# 2. Verify TrustToken signature
jq -r '.trustToken' audit-package.json | openssl dgst -sha256 -verify public-key.pem -signature -

# 3. Verify evidence hashes
jq -r '.evidenceHashes[]' audit-package.json | while read hash; do
  echo "Verifying hash: $hash"
  # Customer recomputes hash from evidence
done

# 4. Verify C2PA signature chain
jq -r '.signatureChain' audit-package.json | c2pa-verify

echo "✅ Audit verification complete"
```

**Expected Gain**: 규제·고객 신뢰 압도적 차별화 (법적 방어력 ↑)

---

### Phase 3.0 Success Criteria (Updated)

**KPIs**:
- [ ] Evidence-UI Match: ≥90%
- [ ] SSR latency: ≤3s
- [ ] Lighthouse score: ≥90
- [ ] Gate V: Pass 100%
- [ ] Mutual Audit: External verification success rate ≥95% ← **NEW**

**Tests**: 910+ passing

**DoD**:
- [ ] Trust Console operational (5 components, 5 API routes)
- [ ] Gate V implemented (Evidence-UI match verification)
- [ ] Mutual Audit Gateway deployed (customer verification tool)
- [ ] SSR performance: p95 < 3s
- [ ] Integration tests: All passing

---

## 6. Data/Model/Infra Preparation

### Required Infrastructure

| Component | Tool/Service | Purpose |
|-----------|--------------|---------|
| Vector DB | FAISS (HNSW/IVF-PQ) | Primary index |
| BM25 Index | Elasticsearch/OpenSearch | Lexical search |
| GPU | 1-2 GPUs (A10/T4) | Batch re-ranking |
| KMS | AWS KMS / Vault | Per-tenant keys |
| Observability | OTel + Prometheus + Grafana | Metrics/Logs |
| Experiment Tracking | MLflow / W&B | Champion-Challenger |
| Cache | Redis / Memcached | Evidence/Embedding cache |

### Model Downloads

```bash
# Cross-Encoder Re-ranker
python -c "from transformers import AutoModel; AutoModel.from_pretrained('BAAI/bge-reranker-large')"

# SPLADE
python -c "from transformers import AutoModel; AutoModel.from_pretrained('naver/splade-cocondenser-ensembledistil')"

# NLI Gate
python -c "from transformers import AutoModel; AutoModel.from_pretrained('microsoft/deberta-v3-large-mnli')"

# Multi-View Embeddings
python -c "from transformers import AutoModel; AutoModel.from_pretrained('BAAI/bge-m3')"
python -c "from transformers import AutoModel; AutoModel.from_pretrained('intfloat/e5-mistral-7b-instruct')"
```

---

## 7. Expected Performance Gains (Cumulative)

| Metric | Baseline | Phase 2.6 | Phase 2.7 | Phase 2.8 | Phase 2.9 | Phase 3.0 | Total Gain |
|--------|----------|-----------|-----------|-----------|-----------|-----------|------------|
| Groundedness | 73% | +8% (81%) | +4% (85%) | - | - | - | **+12%p → 85%** |
| Recall@10 | 100% | +10% (110%) | +5% (115.5%) | +4.5% (120%) | - | - | **+20% → 120%** |
| Readability | 100% | - | +10% (110%) | - | - | - | **+10% → 110%** |
| Cost/1kQA | $100 | - | -10% ($90) | -16.7% ($75) | - | - | **-25% → $75** |
| Compliance | 80% | - | +10%p (90%) | - | +5%p (95%) | - | **+15%p → 95%** |
| Evidence-UI Match | - | - | - | - | - | 90% | **90%** |

---

## 8. Risk Mitigation (Updated)

| Risk | Mitigation (v4.1) |
|------|-------------------|
| 창의성 저하 (규칙 과적합) | Bandit 탐색 + Diversity regularizer + **Contrast sets** |
| 비용 급증 | Pareto Router + 탐색 깊이 동적 제어 + Cache + **GPU batching** |
| 피드백 노이즈 | 신뢰도·반감기·quota + **Federated DP aggregation** |
| 규제 변경 | Policy Watchdog + **Mutual Audit Gateway** |
| 데이터 오염 | SourceTrust + 2+출처 투표 + **Corpus Merkle-DAG** |
| LLM 타임아웃/Rate limit | Router fallback + Cache + **Graceful degradation** |

---

## 9. Integration with RFC 2025-16

이 RFC (v4.1)는 **RFC 2025-16 (v4 Cathedral & Forge)**를 **확장**합니다.

**관계**:
- RFC 2025-16: Baseline architecture + 4-Layer Runtime + Genius Lab
- RFC 2025-17 (this): **Performance maximization upgrades** (Top-15)

**충돌 없음**:
- 모든 업그레이드는 Adapter/Registry 패턴으로 플러그인화
- 기존 Phase 구조 유지 (2.6-3.0, 18주)
- 기존 KPI 목표 유지 (Groundedness 85%, Cost -25%, etc.)

**추가 사항**:
- Quick Wins (6개) → Phase 2.6
- Core Upgrades (6개) → Phase 2.7-2.8
- Strategic (3개) → Phase 2.9-3.0

---

## 10. Conclusion

**v4.1 Performance Maximization**은 기존 v4 계획에 **운영 효율 때문에 넣지 못했던 고급 기술**을 체계적으로 추가합니다.

**핵심 전략**:
1. ✅ **Retrieval-First 강화**: Cross-Encoder + SPLADE + Multi-View + MMR/RRF
2. ✅ **Evidence-Locked 강화**: Constraint Decoding + NLI Gate
3. ✅ **Feedback Loop 강화**: Intent→Param Mapping + Federated DP
4. ✅ **Optimization 강화**: Bandit + Pareto + GPU Batching
5. ✅ **Trust 강화**: Corpus Merkle-DAG + Mutual Audit Gateway

**예상 결과**:
- 정확도·독창성·근거성·안정성 **동시 향상**
- 비용·지연 **최적화** (Pareto Router)
- 규제·감사 **압도적 차별화** (Mutual Audit)

---

**Status**: ✅ Execution Plan Ready
**Next Step**: Phase 2.6 구현 시작 (Quick Wins 6개)
**Timeline**: 18주 (Phase 2.6-3.0)
**Approval**: Pending user confirmation

---

**Last Updated**: 2025-10-09 01:15 KST
**Version**: 1.0
**Related**: RFC 2025-16 (v4 Cathedral & Forge)
