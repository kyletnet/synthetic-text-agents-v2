# ğŸš€ Next Session Quick Start Guide

**Phase 7.1 Intent-Driven RAG - Session 2**

---

## âš¡ Quick Start (5 minutes)

### 1. Verify State
```bash
# Check compilation
npx tsc --noEmit

# Verify Intent Classifier
npx tsx scripts/test-intent-classifier.ts
```

### 2. Create Benchmark Script
```bash
# Copy and modify existing benchmark
cp scripts/real-hybrid-benchmark.ts scripts/real-hybrid-benchmark-intent.ts
```

### 3. Run Benchmark
```bash
# Execute Intent-Driven benchmark
USE_REAL_CLIENTS=true npx tsx scripts/real-hybrid-benchmark-intent.ts
```

### 4. Compare Results
```bash
# Phase 6 baseline
cat reports/hybrid-benchmark/real-benchmark-ragas.json | jq '.summary.ragas'

# Phase 7.1 Intent-Driven
cat reports/hybrid-benchmark/intent-driven-benchmark.json | jq '.summary.ragas'
```

---

## ğŸ“‹ Implementation Checklist

### Benchmark Script Modifications

**File:** `scripts/real-hybrid-benchmark-intent.ts`

**Changes needed:**
1. Import IntentDrivenAdaptiveRAG
```typescript
import { createIntentDrivenAdaptiveRAG } from '../src/runtime/adaptive-rag';
```

2. Replace AdaptiveRAG with IntentDrivenAdaptiveRAG
```typescript
const adaptiveRAG = createIntentDrivenAdaptiveRAG(
  hybridSearchEngine,
  undefined, // LLM generator (optional for Phase 7.1)
  {
    initialK: 2,
    maxK: 6,
    confidenceThreshold: 0.7,
    enableIntentClassification: true,
    enableEvidenceLockedPrompt: true,
    requireCitation: true,
    allowSynthesis: true,
  }
);
```

3. Update result tracking
```typescript
const result = await adaptiveRAG.query({ query, filters: {} });

// Log intent
if (result.intent) {
  console.log(`  Intent: ${result.intent.type} (${result.intent.expectedAnswerType})`);
}

// Log citation compliance
if (result.promptTemplate) {
  console.log(`  Prompt Template Length: ${result.promptTemplate.length}`);
}
```

---

## ğŸ¯ Session Goals

### Primary Goals (Must Complete)
- [ ] Create Intent-Driven benchmark script
- [ ] Execute benchmark with Intent Classification enabled
- [ ] Compare Phase 6 vs Phase 7.1 results
- [ ] Verify citation compliance in answers

### Success Criteria
```
If Relevance improvement > 200%:
  âœ… Proceed to Phase 7.2 (RLRF)

If Relevance improvement 50-200%:
  âš ï¸ Optimize and iterate

If Relevance improvement < 50%:
  ğŸ” Debug Intent Classifier accuracy
```

### Stretch Goals (If Time Permits)
- [ ] Implement citation compliance checker
- [ ] Add LLM-based Intent Classifier (Phase 7.2 prep)
- [ ] Start RLRF weight tracking implementation

---

## ğŸ“‚ Files to Reference

### Current Implementation
```
src/runtime/intent/
â”œâ”€â”€ types.ts                         # Intent types
â”œâ”€â”€ intent-classifier.ts             # Rule-based classifier
â”œâ”€â”€ evidence-locked-prompt.ts        # Prompt builder
â””â”€â”€ index.ts

src/runtime/adaptive-rag/
â”œâ”€â”€ intent-driven-adaptive-rag.ts    # Main implementation
â””â”€â”€ index.ts

docs/RFC/
â””â”€â”€ 2025-Phase7-Self-Evolving-RAG-Network.md  # Architecture
```

### Phase 6 Baseline
```
reports/hybrid-benchmark/
â””â”€â”€ real-benchmark-ragas.json

Current metrics:
- Context Recall: 26.7%
- Context Precision: 9.7%
- Answer Relevance: 4.0%
- Answer Faithfulness: 100%
```

---

## ğŸ”§ Expected Issues & Solutions

### Issue 1: TypeScript Compilation Errors
**Solution:**
```bash
npx tsc --noEmit
# Fix any errors before proceeding
```

### Issue 2: Intent Classification Not Working
**Debug:**
```typescript
// Add logging in intent-driven-adaptive-rag.ts
console.log('[DEBUG] Intent:', JSON.stringify(intent, null, 2));
```

### Issue 3: Citation Not Appearing in Answers
**Check:**
1. Is `enableEvidenceLockedPrompt` set to `true`?
2. Is LLM generator accepting prompt templates?
3. Print `promptTemplate` to verify format

---

## ğŸ“Š Expected Results

### Optimistic Scenario (Best Case)
```
Context Recall:      26.7% â†’ 46.7% (+75%)
Context Precision:   9.7%  â†’ 39.7% (+310%)
Answer Relevance:    4.0%  â†’ 64.0% (+1500%)
Answer Faithfulness: 100%  â†’ 99%+  (maintain)
```

### Realistic Scenario (Expected)
```
Context Recall:      26.7% â†’ 35.0% (+31%)
Context Precision:   9.7%  â†’ 20.0% (+106%)
Answer Relevance:    4.0%  â†’ 30.0% (+650%)
Answer Faithfulness: 100%  â†’ 99%+  (maintain)
```

### Pessimistic Scenario (Worst Case)
```
Context Recall:      26.7% â†’ 30.0% (+12%)
Context Precision:   9.7%  â†’ 15.0% (+55%)
Answer Relevance:    4.0%  â†’ 12.0% (+200%)
Answer Faithfulness: 100%  â†’ 98%+  (acceptable)
```

---

## ğŸš¦ Decision Tree

```
Run Benchmark
    â”‚
    â”œâ”€ Relevance > 50% â”€â”€â”€â†’ âœ… Success! Continue to Phase 7.2 (RLRF)
    â”‚
    â”œâ”€ Relevance 30-50% â”€â”€â†’ âš ï¸ Partial Success
    â”‚                         â”œâ”€ Debug Intent Classification
    â”‚                         â”œâ”€ Tune Prompt Template
    â”‚                         â””â”€ Iterate
    â”‚
    â””â”€ Relevance < 30% â”€â”€â”€â”€â†’ ğŸ” Debug Mode
                              â”œâ”€ Check Intent Accuracy
                              â”œâ”€ Verify Prompt Generation
                              â”œâ”€ Review LLM Generator
                              â””â”€ Consider LLM-based Classifier
```

---

## ğŸ“ Learning Resources

### Intent Classification Patterns
```typescript
// Factual (ì‚¬ì‹¤)
"ì–¼ë§ˆ", "ì–¸ì œ", "ë¬´ì—‡", "ì–´ë””" + ìˆ«ì

// Procedural (ì ˆì°¨)
"ì–´ë–»ê²Œ", "ë°©ë²•", "ì‹ ì²­", "ì´ìš©", "ì ˆì°¨"

// Comparative (ë¹„êµ)
"ì°¨ì´", "ë¹„êµ", "ë‹¤ë¥¸", "ë˜ëŠ”", "ë”"

// Explanatory (ì„¤ëª…)
"ì™œ", "ì´ìœ ", "ì„¤ëª…", "ëœ»"

// Aggregative (ì§‘ê³„)
"ì „ì²´", "ëª¨ë‘", "ì´", "ìš”ì•½"
```

### Evidence-Locked Prompt Rules
```
Rule 1: Evidence-Only (Context ì™¸ ì •ë³´ ì‚¬ìš© ê¸ˆì§€)
Rule 2: Citation Required ([Context N] í‘œê¸° í•„ìˆ˜)
Rule 3: Exact Citation (ìˆ˜ì¹˜/ë‚ ì§œ ì›ë¬¸ ê·¸ëŒ€ë¡œ)
Rule 4: No-Info Fallback (ì •ë³´ ì—†ìŒ ëª…ì‹œ)
Rule 5: Synthesis Allowed (ì—¬ëŸ¬ Context í†µí•©)
Rule 6: Hallucination Penalty (ìœ„ë°˜ ì‹œ ê±°ë¶€)
```

---

## ğŸ“ Support Commands

### Debug Commands
```bash
# View Intent Classifier implementation
cat src/runtime/intent/intent-classifier.ts | grep -A 20 "detectIntentType"

# View Evidence-Locked Prompt template
cat src/runtime/intent/evidence-locked-prompt.ts | grep -A 30 "buildRulesSection"

# View current baseline
cat reports/hybrid-benchmark/real-benchmark-ragas.json | jq '.summary'

# Check TypeScript errors
npx tsc --noEmit | grep "error TS"
```

### Performance Analysis
```bash
# Compare recall
jq -s '.[0].summary.ragas.contextRecall as $old | .[1].summary.ragas.contextRecall as $new | ($new - $old) / $old * 100' \
  reports/hybrid-benchmark/real-benchmark-ragas.json \
  reports/hybrid-benchmark/intent-driven-benchmark.json

# Compare precision
jq -s '.[0].summary.ragas.contextPrecision as $old | .[1].summary.ragas.contextPrecision as $new | ($new - $old) / $old * 100' \
  reports/hybrid-benchmark/real-benchmark-ragas.json \
  reports/hybrid-benchmark/intent-driven-benchmark.json
```

---

## âœ… Pre-Flight Checklist

Before starting Session 2:
- [ ] Read `PHASE_7_SESSION_1_COMPLETE.md`
- [ ] Verify `npx tsc --noEmit` passes
- [ ] Run `npx tsx scripts/test-intent-classifier.ts`
- [ ] Confirm Phase 6 baseline in `real-benchmark-ragas.json`
- [ ] Check Elasticsearch is running: `curl localhost:9200`
- [ ] Clear FAISS index if needed: `rm -rf data/faiss-index`

---

## ğŸ Start Command

```bash
# When ready, execute:
npx tsx scripts/real-hybrid-benchmark-intent.ts

# Expected runtime: ~3-5 minutes
# Expected output: reports/hybrid-benchmark/intent-driven-benchmark.json
```

---

**Good luck! ğŸš€**
**Target: +650% Answer Relevance improvement**
