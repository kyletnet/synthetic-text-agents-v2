import Anthropic from "@anthropic-ai/sdk";
import { LLMCallManager, recordLLMCall } from "./llm-call-manager";
import { apiKeyManager } from "./api-key-manager";
import { guardLLMClient, GuardedLLMClient } from "./universal-llm-guard";

export class AnthropicClient {
  private client: Anthropic | null = null;
  private initialized = false;

  constructor() {
    this.initialize();
  }

  private initialize() {
    // API Key Managerì—ì„œ í˜„ì¬ í‚¤ í™•ì¸
    const apiKey = apiKeyManager.getCurrentKey();

    if (!apiKey) {
      console.warn(
        "No valid API keys available. LLM features will be disabled.",
      );
      console.warn("API Key Manager Stats:", apiKeyManager.getStats());
      return;
    }

    try {
      this.client = new Anthropic({
        apiKey: apiKey,
      });
      this.initialized = true;
      const stats = apiKeyManager.getStats();
      console.log(
        `Anthropic client initialized with ${stats.activeKeys}/${stats.totalKeys} available keys`,
      );
    } catch (error) {
      console.error("Failed to initialize Anthropic client:", error);
      // í˜„ì¬ í‚¤ë¥¼ ì‹¤íŒ¨ë¡œ ê¸°ë¡
      if (apiKey) {
        apiKeyManager.recordFailure(apiKey, error);
      }
    }
  }

  isReady(): boolean {
    // API Key Managerì— ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤ê°€ ìˆëŠ”ì§€ ì²´í¬
    if (!apiKeyManager.hasAvailableKeys()) {
      console.error("âŒ No available API keys - system cannot function");
      return false;
    }

    return this.initialized && this.client !== null;
  }

  async generateText(
    prompt: string,
    maxTokens: number = 1000,
    sessionId: string = "default",
  ): Promise<string> {
    if (!this.isReady()) {
      throw new Error(
        "âŒ CRITICAL: No valid API keys available. System cannot function without proper API configuration.",
      );
    }

    // API í‚¤ ë¡œí…Œì´ì…˜ì„ ì§€ì›í•˜ëŠ” í–¥ìƒëœ í˜¸ì¶œ ë¡œì§
    let lastError: Error | null = null;
    let attempts = 0;
    const maxAttempts = Math.min(3, apiKeyManager.getStats().activeKeys); // ìµœëŒ€ 3íšŒ ë˜ëŠ” í™œì„± í‚¤ ìˆ˜ë§Œí¼

    while (attempts < maxAttempts) {
      const currentKey = apiKeyManager.getCurrentKey();

      if (!currentKey) {
        throw new Error("âŒ CRITICAL: All API keys exhausted. Cannot proceed.");
      }

      try {
        // í´ë¼ì´ì–¸íŠ¸ë¥¼ í˜„ì¬ í‚¤ë¡œ ì¬ì´ˆê¸°í™” (í‚¤ê°€ ë°”ë€Œì—ˆì„ ìˆ˜ ìˆìŒ)
        this.client = new Anthropic({
          apiKey: currentKey,
        });

        // LLMCallManagerë¡œ ê´€ë¦¬ë˜ëŠ” ì‹¤ì œ API í˜¸ì¶œ
        const result = await LLMCallManager.callWithRetry(
          sessionId,
          async () => {
            const response = await this.client!.messages.create({
              model: "claude-3-haiku-20240307",
              max_tokens: maxTokens,
              messages: [
                {
                  role: "user",
                  content: prompt,
                },
              ],
            });

            if (response.content[0].type === "text") {
              return response.content[0].text;
            } else {
              throw new Error("Unexpected response format from Anthropic API");
            }
          },
          "generateText",
        );

        if (result.success) {
          // ì„±ê³µì ì¸ API í˜¸ì¶œ ê¸°ë¡
          apiKeyManager.recordSuccess(currentKey);
          return result.data as string;
        } else {
          // ì‹¤íŒ¨ ê¸°ë¡ ë° ë‹¤ìŒ í‚¤ë¡œ ì‹œë„
          apiKeyManager.recordFailure(currentKey, result.error);
          lastError = result.error || new Error("Unknown LLM call error");
          attempts++;
          continue;
        }
      } catch (error) {
        // ì§ì ‘ì ì¸ API ì—ëŸ¬ ì²˜ë¦¬
        console.warn(
          `API call failed with key ${
            apiKeyManager.getStats().currentKeyIndex + 1
          }: ${error}`,
        );
        apiKeyManager.recordFailure(currentKey, error);
        lastError = error as Error;
        attempts++;
      }
    }

    // ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
    const stats = apiKeyManager.getStats();
    throw new Error(
      `âŒ CRITICAL: Failed to generate text after ${attempts} attempts. ` +
        `Active keys: ${stats.activeKeys}/${stats.totalKeys}. ` +
        `Last error: ${lastError?.message || "Unknown error"}`,
    );
  }

  async generateAugmentation(
    input: string,
    augmentationType: string,
    ragContext?: string,
    sessionId: string = "default",
  ): Promise<string> {
    let prompt = "";

    switch (augmentationType) {
      case "paraphrase":
        prompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”. ì˜ë¯¸ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ë©´ì„œ í‘œí˜„ë§Œ ë°”ê¿”ì£¼ì„¸ìš”:

ì›ë³¸: ${input}

${
  ragContext ? `ì°¸ê³  ìë£Œ:\n${ragContext}\n\n` : ""
}ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„ëœ í…ìŠ¤íŠ¸:`;
        break;

      case "extend":
        prompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë” ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ í™•ì¥í•´ì£¼ì„¸ìš”:

ì›ë³¸: ${input}

${ragContext ? `ì°¸ê³  ìë£Œ:\n${ragContext}\n\n` : ""}í™•ì¥ëœ í…ìŠ¤íŠ¸:`;
        break;

      case "summarize":
        prompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ì›ë³¸: ${input}

${ragContext ? `ì°¸ê³  ìë£Œ:\n${ragContext}\n\n` : ""}ìš”ì•½:`;
        break;

      case "qa_generation":
        prompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸-ë‹µë³€ ìŒì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

ì›ë³¸: ${input}

${
  ragContext ? `ì°¸ê³  ìë£Œ:\n${ragContext}\n\n` : ""
}ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:`;
        break;

      case "style_transfer":
        prompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë” ê²©ì‹ìˆëŠ” ë¬¸ì²´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:

ì›ë³¸: ${input}

${
  ragContext ? `ì°¸ê³  ìë£Œ:\n${ragContext}\n\n` : ""
}ê²©ì‹ìˆëŠ” ë¬¸ì²´ë¡œ ë³€í™˜ëœ í…ìŠ¤íŠ¸:`;
        break;

      default:
        prompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”:

ì›ë³¸: ${input}

${ragContext ? `ì°¸ê³  ìë£Œ:\n${ragContext}\n\n` : ""}ê°œì„ ëœ í…ìŠ¤íŠ¸:`;
    }

    return await this.generateText(prompt, 2000, sessionId);
  }

  async evaluateQuality(
    original: string,
    augmented: string,
    sessionId: string = "default",
  ): Promise<{
    score: number;
    metrics: {
      semantic_similarity: number;
      fluency: number;
      coherence: number;
      usefulness: number;
    };
  }> {
    if (!this.isReady()) {
      return {
        score: 0.7,
        metrics: {
          semantic_similarity: 0.7,
          fluency: 0.7,
          coherence: 0.7,
          usefulness: 0.7,
        },
      };
    }

    const evaluationPrompt = `ë‹¤ìŒ ì›ë³¸ê³¼ ë³€í˜•ëœ í…ìŠ¤íŠ¸ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”. ê° í•­ëª©ì„ 0.0~1.0 ì‚¬ì´ì˜ ì ìˆ˜ë¡œ ë§¤ê²¨ì£¼ì„¸ìš”.

ì›ë³¸: ${original}

ë³€í˜•: ${augmented}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
{
  "semantic_similarity": 0.0-1.0ì  (ì˜ë¯¸ì  ìœ ì‚¬ì„±),
  "fluency": 0.0-1.0ì  (ë¬¸ì¥ì˜ ìì—°ìŠ¤ëŸ¬ì›€),
  "coherence": 0.0-1.0ì  (ë…¼ë¦¬ì  ì¼ê´€ì„±),
  "usefulness": 0.0-1.0ì  (ì‹¤ìš©ì  ê°€ì¹˜)
}

JSONë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”:`;

    try {
      const response = await this.generateText(
        evaluationPrompt,
        500,
        sessionId,
      );
      const evaluation = JSON.parse(response);

      const score =
        (evaluation.semantic_similarity +
          evaluation.fluency +
          evaluation.coherence +
          evaluation.usefulness) /
        4;

      return {
        score: Math.min(Math.max(score, 0), 1),
        metrics: {
          semantic_similarity: Math.min(
            Math.max(evaluation.semantic_similarity, 0),
            1,
          ),
          fluency: Math.min(Math.max(evaluation.fluency, 0), 1),
          coherence: Math.min(Math.max(evaluation.coherence, 0), 1),
          usefulness: Math.min(Math.max(evaluation.usefulness, 0), 1),
        },
      };
    } catch (error) {
      console.error("Quality evaluation failed:", error);
      return {
        score: 0.7,
        metrics: {
          semantic_similarity: 0.7,
          fluency: 0.7,
          coherence: 0.7,
          usefulness: 0.7,
        },
      };
    }
  }
}

// ğŸ›¡ï¸ Create guarded anthropic client instance
const rawAnthropicClient = new AnthropicClient();

// ğŸ¯ Apply Universal Guard System
export const anthropicClient = guardLLMClient(
  rawAnthropicClient,
  "AnthropicClient",
) as AnthropicClient & GuardedLLMClient;

// ğŸ“Š Log guard injection status
console.log(
  `ğŸ›¡ï¸ AnthropicClient guard injection: ${
    anthropicClient._isGuarded ? "ACTIVE" : "DISABLED"
  }`,
);

// ğŸ” Export raw client for internal testing (DO NOT USE DIRECTLY)
export const _rawAnthropicClient = rawAnthropicClient;
