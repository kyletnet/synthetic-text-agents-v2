#!/usr/bin/env tsx
/**
 * End-to-End PDF ‚Üí QA Generation Test
 *
 * Complete pipeline test:
 * 1. PDF Ingest ‚Üí Chunks
 * 2. Guideline ‚Üí GCG Rules
 * 3. LLM ‚Üí QA Generation
 * 4. Gate G ‚Üí Compliance Validation
 * 5. Gate F ‚Üí Performance Monitoring
 * 6. Report Generation
 *
 * Usage:
 *   npx tsx scripts/e2e-pdf-qa-test.ts
 *
 * Environment Variables:
 *   LLM_PROVIDER=claude|openai|mock (default: mock)
 *   ANTHROPIC_API_KEY=your-key
 *   LLM_MODEL=claude-3-5-sonnet-20241022
 *
 * Exit Criteria:
 *   - Guideline Compliance ‚â• 90%
 *   - Groundedness ‚â• 85%
 *   - p95 Latency ‚â§ 10ms
 */

import * as fs from 'fs';
import * as path from 'path';
import { LLMProvider } from '../src/clients/llm-provider';
import { GCGCompiler, type Grammar } from '../src/offline/genius-lab/gcg/compiler';
import { GCGValidator } from '../src/offline/genius-lab/gcg/validator';
import { GateGController } from '../src/runtime/optimization/gate-g-guideline';
import { GateFController } from '../src/runtime/optimization/gate-f-throughput';
import { PDFIngestor } from '../src/infrastructure/retrieval/pdf-ingestor';
import { EvidenceStore } from '../src/core/transparency/evidence-store';
import type { QAPair } from '../src/application/qa-generator';
import type { PDFChunk } from '../src/infrastructure/retrieval/pdf-ingestor';

/**
 * Configuration
 */
const CONFIG = {
  // Paths
  guidelinePath: path.join(
    process.cwd(),
    'datasets/qa-guideline-test/guideline/Î¨∏ÏÑúÎ≥Ñ QA ÏÉùÏÑ± Í∞ÄÏù¥ÎìúÎùºÏù∏ 27258518f3ab809f925eff15d6ecd1ac.md'
  ),
  pdfPath: path.join(process.cwd(), 'datasets/qa-guideline-test/documents/2024ÎÖÑ_ÏïÑÏù¥ÎèåÎ¥ÑÏßÄÏõêÏÇ¨ÏóÖ_ÏïàÎÇ¥.pdf'),
  outputPath: path.join(process.cwd(), 'reports/e2e-pdf-qa-test'),

  // QA Generation
  qaPerDocument: 10,
  maxRetries: 3,
  minValidationScore: 80,

  // Gate thresholds
  gateG: {
    minCompliance: 80, // 80% for testing (90% for production)
    minScore: 80,
  },
  gateF: {
    maxP95Latency: 50.0, // 50ms for testing (10ms for production)
    minThroughput: 20, // 20 q/s for testing (400 q/s for production)
  },
};


/**
 * Main test flow
 */
async function main() {
  console.log('üöÄ E2E PDF ‚Üí QA Test Starting...\n');
  console.log('‚ïê'.repeat(60));

  const startTime = performance.now();

  // Step 1: Initialize components
  console.log('\nüì¶ Step 1: Initialize Components\n');

  const llmProvider = new LLMProvider({
    provider: (process.env.LLM_PROVIDER as any) || 'mock',
    apiKey: process.env.ANTHROPIC_API_KEY,
  });

  console.log(`   LLM Provider: ${llmProvider.getConfig().provider}`);
  console.log(`   Model: ${llmProvider.getConfig().model}`);
  console.log(`   Ready: ${llmProvider.isReady() ? '‚úÖ' : '‚ùå'}\n`);

  const gcgCompiler = new GCGCompiler();
  const gcgValidator = new GCGValidator();

  const gateG = new GateGController({
    guidelinePath: CONFIG.guidelinePath,
    minCompliance: CONFIG.gateG.minCompliance,
    minScore: CONFIG.gateG.minScore,
  });

  const gateF = new GateFController({
    maxP95Latency: CONFIG.gateF.maxP95Latency,
    minThroughput: CONFIG.gateF.minThroughput,
  });

  // Step 2: Compile guideline
  console.log('üìò Step 2: Compile Guideline\n');

  if (!fs.existsSync(CONFIG.guidelinePath)) {
    throw new Error(`Guideline not found: ${CONFIG.guidelinePath}`);
  }

  const grammar = gcgCompiler.compile(CONFIG.guidelinePath);
  console.log(`   ‚úÖ Grammar compiled (domain: ${grammar.domain})`);
  console.log(`   Rules: ${Object.keys(grammar.rules).length} categories\n`);

  // Step 3: Load chunks from PDF
  console.log('üìÑ Step 3: Ingest PDF Document\n');

  const evidenceStore = new EvidenceStore();
  const pdfIngestor = new PDFIngestor(evidenceStore);

  console.log(`   Processing: ${path.basename(CONFIG.pdfPath)}`);
  const pdfResult = await pdfIngestor.ingestPDF(CONFIG.pdfPath);

  if (!pdfResult.success) {
    throw new Error(`PDF ingestion failed: ${pdfResult.error}`);
  }

  const chunks = pdfResult.chunks;
  console.log(`   ‚úÖ Extracted ${pdfResult.totalPages} pages ‚Üí ${chunks.length} chunks`);
  console.log(`   Text: ${pdfResult.extractedText.length} characters\n`);

  // Step 4: Generate QA pairs
  console.log(`ü§ñ Step 4: Generate ${CONFIG.qaPerDocument} QA Pairs\n`);

  const qaPairs: QAPair[] = [];
  const generationLatencies: number[] = [];

  for (let i = 0; i < Math.min(CONFIG.qaPerDocument, chunks.length); i++) {
    const chunk = chunks[i % chunks.length];
    const qaStartTime = performance.now();

    try {
      const qa = await generateQA(llmProvider, chunk, grammar, gcgValidator, i + 1);

      if (qa) {
        qaPairs.push(qa);
        const latency = performance.now() - qaStartTime;
        generationLatencies.push(latency);

        // Record in Gate F
        gateF.recordMeasurement(latency, 1);

        console.log(`  ‚úì Generated QA ${i + 1}/${CONFIG.qaPerDocument} (score: ${qa.metadata.validationScore})`);
      } else {
        console.log(`  ‚úó Failed QA ${i + 1}/${CONFIG.qaPerDocument}`);
      }
    } catch (error) {
      console.error(`  ‚úó Error QA ${i + 1}/${CONFIG.qaPerDocument}:`, error);
    }
  }

  console.log(`\n‚úÖ QA Generation Complete`);
  console.log(`   Generated: ${qaPairs.length}/${CONFIG.qaPerDocument}`);
  console.log(`   Valid: ${qaPairs.length}/${CONFIG.qaPerDocument}`);
  console.log(
    `   Compliance: ${qaPairs.length > 0 ? ((qaPairs.length / CONFIG.qaPerDocument) * 100).toFixed(1) : 0}%`
  );

  const avgLatency = generationLatencies.reduce((sum, l) => sum + l, 0) / generationLatencies.length;
  console.log(`   Duration: ${avgLatency.toFixed(2)}ms\n`);

  // Step 5: Validate with Gate G
  console.log('üìä Step 5: Gate G Validation\n');

  const gateGResult = gateG.validateQA(qaPairs);

  // Calculate metrics from results
  const totalQA = gateGResult.results.length;
  const validQA = gateGResult.results.filter((r) => r.passed).length;
  const avgScore = gateGResult.results.reduce((sum, r) => sum + r.score, 0) / totalQA || 0;
  const totalViolations = gateGResult.results.reduce((sum, r) => sum + r.violations, 0);

  console.log(`   Total QA: ${totalQA}`);
  console.log(`   Valid QA: ${validQA}`);
  console.log(`   Compliance: ${gateGResult.complianceRate.toFixed(1)}%`);
  console.log(`   Average Score: ${avgScore.toFixed(1)}/100`);
  console.log(`   Violations: ${totalViolations}`);
  console.log(`   Status: ${gateGResult.passed ? '‚úÖ PASS' : '‚ùå FAIL'}\n`);

  // Step 6: Check Gate F
  console.log('üìä Step 6: Gate F Status\n');

  const gateFStatus = gateF.getStatus();

  console.log(`   Status: ${gateF.passes() ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  console.log(`   p95 Latency: ${gateFStatus.metrics.p95Latency.toFixed(3)}ms`);
  console.log(`   Throughput: ${gateFStatus.metrics.throughput.toFixed(0)} q/s`);
  console.log(`   System Utilization: ${(gateFStatus.metrics.systemUtilization * 100).toFixed(1)}%\n`);

  // Step 7: Generate report
  console.log('üìù Step 7: Generate Report\n');

  const duration = performance.now() - startTime;

  const report = {
    timestamp: new Date().toISOString(),
    config: CONFIG,
    results: {
      qaGeneration: {
        requested: CONFIG.qaPerDocument,
        generated: qaPairs.length,
        avgLatency: avgLatency.toFixed(2) + 'ms',
      },
      gateG: {
        status: gateGResult.passed ? 'PASS' : 'FAIL',
        complianceRate: gateGResult.complianceRate,
        validQA,
        totalQA,
        averageScore: avgScore,
        violations: totalViolations,
      },
      gateF: {
        status: gateF.passes() ? 'PASS' : 'FAIL',
        p95Latency: gateFStatus.metrics.p95Latency,
        throughput: gateFStatus.metrics.throughput,
        systemUtilization: gateFStatus.metrics.systemUtilization,
      },
      overallStatus: gateGResult.passed && gateF.passes() ? 'PASS' : 'FAIL',
      duration: duration.toFixed(2) + 'ms',
    },
    qaPairs,
  };

  // Save report
  if (!fs.existsSync(CONFIG.outputPath)) {
    fs.mkdirSync(CONFIG.outputPath, { recursive: true });
  }

  const reportPath = path.join(CONFIG.outputPath, 'test-report.json');
  fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));

  console.log(`   ‚úÖ Report saved: ${reportPath}\n`);

  // Final summary
  console.log('‚ïê'.repeat(60));
  console.log('üìä FINAL SUMMARY');
  console.log('‚ïê'.repeat(60));
  console.log(`   Overall Status: ${report.results.overallStatus === 'PASS' ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  console.log(`   QA Generated: ${qaPairs.length}/${CONFIG.qaPerDocument}`);
  console.log(`   Gate G: ${gateGResult.passed ? '‚úÖ PASS' : '‚ùå FAIL'} (${gateGResult.complianceRate.toFixed(1)}%)`);
  console.log(`   Gate F: ${gateF.passes() ? '‚úÖ PASS' : '‚ùå FAIL'} (${gateFStatus.metrics.p95Latency.toFixed(2)}ms)`);
  console.log(`   Duration: ${(duration / 1000).toFixed(2)}s`);
  console.log('‚ïê'.repeat(60) + '\n');

  // Exit with appropriate code
  if (report.results.overallStatus !== 'PASS') {
    console.error('‚ùå Test FAILED - Check report for details');
    process.exit(1);
  }

  console.log('‚úÖ Test PASSED - All gates passed');
  process.exit(0);
}

/**
 * Generate single QA pair with LLM + GCG validation
 */
async function generateQA(
  llmProvider: LLMProvider,
  chunk: PDFChunk,
  grammar: Grammar,
  validator: GCGValidator,
  index: number
): Promise<QAPair | null> {
  const maxRetries = CONFIG.maxRetries;
  let retries = 0;

  while (retries < maxRetries) {
    try {
      // Build system prompt with GCG rules
      const systemPrompt = buildSystemPrompt(grammar);

      // Build user prompt with chunk content
      const userPrompt = buildUserPrompt(chunk);

      // Call LLM
      const response = await llmProvider.generate({
        systemPrompt,
        userPrompt,
        maxTokens: 1024,
        temperature: 0.7,
      });

      // Parse response
      const { question, answer } = parseQAResponse(response.content);

      // Validate with GCG
      const questionValidation = validator.validate(question, grammar);
      const answerValidation = validator.validate(answer, grammar);

      const avgScore = (questionValidation.score + answerValidation.score) / 2;
      const violations =
        questionValidation.violations.filter((v) => v.severity === 'error').length +
        answerValidation.violations.filter((v) => v.severity === 'error').length;

      // Check if meets minimum score
      if (avgScore >= CONFIG.minValidationScore) {
        return {
          id: `qa-${chunk.id}-${index}`,
          question,
          answer,
          sourceChunks: [chunk.id],
          metadata: {
            domain: grammar.domain,
            questionType: detectQuestionType(question),
            difficulty: 'medium',
            generatedAt: new Date().toISOString(),
            validationScore: avgScore,
            violations,
          },
        };
      }

      retries++;
    } catch (error) {
      retries++;
      console.error(`    Retry ${retries}/${maxRetries}:`, error);
    }
  }

  return null;
}

/**
 * Build system prompt with GCG rules
 */
function buildSystemPrompt(grammar: Grammar): string {
  // Extract grammar rules with type safety
  const numberFormat = grammar.rules.number_format
    ? `ÌòïÏãù: ${grammar.rules.number_format.format}, Îã®ÏúÑ: ${grammar.rules.number_format.allowed_units.join('/')}`
    : 'ÏïÑÎùºÎπÑÏïÑ Ïà´Ïûê ÏÇ¨Ïö©';

  const tone = grammar.rules.tone
    ? `${grammar.rules.tone.formality} ÌÜ§ (${grammar.rules.tone.allowed.join(', ')})`
    : 'Ï†ïÏ§ëÌïú Ïñ¥Ï°∞ ÏÇ¨Ïö©';

  const forbidden = grammar.rules.forbidden
    ? `Í∏àÏßÄ Ìå®ÌÑ¥: ${grammar.rules.forbidden.ngrams.slice(0, 3).join(', ')}${grammar.rules.forbidden.ngrams.length > 3 ? ' Îì±' : ''}`
    : 'Î∂ÄÏ†ÅÏ†àÌïú ÌëúÌòÑ Í∏àÏßÄ';

  return `ÎãπÏã†ÏùÄ ${grammar.domain} ÎèÑÎ©îÏù∏Ïùò QA ÏåçÏùÑ ÏÉùÏÑ±ÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.

Îã§Ïùå Í∞ÄÏù¥ÎìúÎùºÏù∏ÏùÑ Î∞òÎìúÏãú Ï§ÄÏàòÌïòÏÑ∏Ïöî:

1. **Ïà´Ïûê ÌòïÏãù**: ${numberFormat}
2. **ÌÜ§**: ${tone}
3. **Í∏àÏßÄ ÏÇ¨Ìï≠**: ${forbidden}

ÏùëÎãµ ÌòïÏãù (JSON):
{
  "question": "ÏßàÎ¨∏ ÎÇ¥Ïö©",
  "answer": "ÎãµÎ≥Ä ÎÇ¥Ïö©"
}

Ï§ëÏöî:
- ÏßàÎ¨∏Í≥º ÎãµÎ≥ÄÏùÄ Î∞òÎìúÏãú Ï†úÍ≥µÎêú Ïª®ÌÖçÏä§Ìä∏Ïóê Í∑ºÍ±∞Ìï¥Ïïº Ìï©ÎãàÎã§
- Ïà´ÏûêÎäî Ï†ïÌôïÌïòÍ≤å ÌëúÍ∏∞ÌïòÏÑ∏Ïöî
- Ï°¥ÎåìÎßêÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî
- JSON ÌòïÏãùÏúºÎ°úÎßå ÏùëÎãµÌïòÏÑ∏Ïöî`;
}

/**
 * Build user prompt with chunk content
 */
function buildUserPrompt(chunk: PDFChunk): string {
  return `Îã§Ïùå Î¨∏ÏÑú ÎÇ¥Ïö©ÏùÑ Í∏∞Î∞òÏúºÎ°ú ÏßàÎ¨∏-ÎãµÎ≥Ä ÏåçÏùÑ ÏÉùÏÑ±ÌïòÏÑ∏Ïöî:

„ÄêÎ¨∏ÏÑú ÎÇ¥Ïö©„Äë
${chunk.text}

„ÄêÏöîÍµ¨ÏÇ¨Ìï≠„Äë
- ÏßàÎ¨∏: Î¨∏ÏÑú ÎÇ¥Ïö©Ïóê ÎåÄÌïú Î™ÖÌôïÌïú ÏßàÎ¨∏
- ÎãµÎ≥Ä: Î¨∏ÏÑú ÎÇ¥Ïö©Ïóê Í∑ºÍ±∞Ìïú Ï†ïÌôïÌïú ÎãµÎ≥Ä
- ÌòïÏãù: JSON {"question": "...", "answer": "..."}

JSON ÏùëÎãµ:`;
}

/**
 * Parse QA response from LLM
 */
function parseQAResponse(content: string): { question: string; answer: string } {
  try {
    // Try to parse as JSON
    const parsed = JSON.parse(content);
    if (parsed.question && parsed.answer) {
      return {
        question: parsed.question,
        answer: parsed.answer,
      };
    }
  } catch {
    // If not JSON, try to extract from text
    const questionMatch = content.match(/["']?question["']?\s*:\s*["'](.+?)["']/i);
    const answerMatch = content.match(/["']?answer["']?\s*:\s*["'](.+?)["']/i);

    if (questionMatch && answerMatch) {
      return {
        question: questionMatch[1],
        answer: answerMatch[1],
      };
    }
  }

  throw new Error('Failed to parse QA from response');
}

/**
 * Detect question type
 */
function detectQuestionType(question: string): string {
  if (question.includes('Î¨¥Ïóá') || question.includes('Î≠ê')) return 'what';
  if (question.includes('Ïñ¥ÎñªÍ≤å') || question.includes('Î∞©Î≤ï')) return 'how';
  if (question.includes('Ïôú')) return 'why';
  if (question.includes('Ïñ∏Ï†ú')) return 'when';
  if (question.includes('Ïñ¥Îîî')) return 'where';
  if (question.includes('ÎàÑÍµ¨')) return 'who';
  return 'general';
}

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch((error) => {
    console.error('‚ùå Test failed:', error);
    process.exit(1);
  });
}
